{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Transformer Block \\\n",
    "The TransformerBlock consists of:\n",
    "\n",
    "Multihead Attention: To capture relationships between tokens in the sequence.\n",
    "\n",
    "Layer Normalization: To stabilize training.\n",
    "\n",
    "Feedforward Network: To process the attention output.\n",
    "\n",
    "Dropout: For regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, n_heads, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: Dimensionality of the input embeddings.\n",
    "            n_heads: Number of attention heads.\n",
    "            dropout: Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        # Multihead Attention\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, n_heads, dropout=dropout)\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Feedforward Network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),  # Expand dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim)   # Compress back to original dimension\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (seq_len, batch_size, embed_dim).\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor of shape (seq_len, batch_size, embed_dim).\n",
    "        \"\"\"\n",
    "        # Multihead Attention\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)  # Self-attention\n",
    "        x = x + self.dropout(attn_output)              # Residual connection\n",
    "        x = self.norm1(x)                              # Layer normalization\n",
    "        \n",
    "        # Feedforward Network\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = x + self.dropout(ffn_output)               # Residual connection\n",
    "        x = self.norm2(x)                              # Layer normalization\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Testing the Updated Dataset\\\n",
    "Let's test the updated dataset to ensure the combined embeddings are in the correct shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in TCR embeddings file: ['embeddings', 'labels']\n",
      "Keys in Epitope embeddings file: ['embeddings']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the .npz files\n",
    "tcr_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz')\n",
    "epitope_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_Epitope_embeddings.npz')\n",
    "\n",
    "# Print the keys in each file\n",
    "print(\"Keys in TCR embeddings file:\", list(tcr_data.keys()))\n",
    "print(\"Keys in Epitope embeddings file:\", list(epitope_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK!!  \n",
    "\\\n",
    "Step 1: Verify the Size of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TCR embeddings: 570500\n",
      "Number of epitope embeddings: 570500\n"
     ]
    }
   ],
   "source": [
    "# Load the TCR and epitope embeddings\n",
    "tcr_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz')\n",
    "epitope_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_Epitope_embeddings.npz')\n",
    "\n",
    "tcr_embeddings = tcr_data['embeddings']  # Use the correct key\n",
    "epitope_embeddings = epitope_data['embeddings']  # Use the correct key\n",
    "\n",
    "print(f\"Number of TCR embeddings: {len(tcr_embeddings)}\")\n",
    "print(f\"Number of epitope embeddings: {len(epitope_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Ensure Labels Match the Dataset Size\\\n",
    "If you have labels, ensure the labels array has the same length as the number of TCR/epitope embeddings. If you don't have labels, we can create dummy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 570500\n"
     ]
    }
   ],
   "source": [
    "# If you have labels, load them here\n",
    "path_to_labels = '/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz'\n",
    "labels_data = np.load(path_to_labels)  # Example: Load labels from a file\n",
    "labels = labels_data['labels']\n",
    "\n",
    "# If you don't have labels, create dummy labels\n",
    "# labels = np.zeros(len(tcr_embeddings))  # Dummy labels (all zeros)\n",
    "\n",
    "print(f\"Number of labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation and test\\\n",
    "This is only a dummy splitting, since for real testing we'll use \n",
    "a separate test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% training\n",
    "val_size = len(dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Update the Dataset Class \\\n",
    "Update the TCR_Epitope_Dataset class to ensure it uses the correct indices and handles the dataset size properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCR_Epitope_Dataset(Dataset):\n",
    "    def __init__(self, tcr_embeddings, epitope_embeddings, labels=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tcr_embeddings: Array of TCR embeddings.\n",
    "            epitope_embeddings: Array of epitope embeddings.\n",
    "            labels: Optional array of labels (1 for binding, 0 for non-binding).\n",
    "        \"\"\"\n",
    "        self.tcr_embeddings = tcr_embeddings\n",
    "        self.epitope_embeddings = epitope_embeddings\n",
    "        \n",
    "        # Ensure the number of TCR and epitope embeddings match\n",
    "        assert len(self.tcr_embeddings) == len(self.epitope_embeddings), \\\n",
    "            \"Number of TCR and epitope embeddings must match!\"\n",
    "        \n",
    "        # If labels are provided, use them; otherwise, create dummy labels\n",
    "        self.labels = labels if labels is not None else np.zeros(len(self.tcr_embeddings))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tcr_embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            combined_embedding: Combined TCR and epitope embeddings of shape (2, 1024).\n",
    "            label: Binding label (1 or 0).\n",
    "        \"\"\"\n",
    "        tcr_embedding = self.tcr_embeddings[idx]\n",
    "        epitope_embedding = self.epitope_embeddings[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        tcr_embedding = torch.tensor(tcr_embedding, dtype=torch.float32)\n",
    "        epitope_embedding = torch.tensor(epitope_embedding, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # Combine TCR and epitope embeddings along the sequence dimension\n",
    "        combined_embedding = torch.stack([tcr_embedding, epitope_embedding], dim=0)  # Shape: (2, 1024)\n",
    "        \n",
    "        return combined_embedding, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Create the Dataset and DataLoader \\\n",
    "Now, create the dataset and DataLoader with the correct data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 570500\n",
      "Combined embedding shape: torch.Size([2, 1024])\n",
      "Label: 1.0\n",
      "Combined embeddings batch shape: torch.Size([32, 2, 1024])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = TCR_Epitope_Dataset(tcr_embeddings, epitope_embeddings, labels)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(f\"Number of samples: {len(dataset)}\")\n",
    "combined_embedding, label = dataset[0]  # Get the first sample\n",
    "print(f\"Combined embedding shape: {combined_embedding.shape}\")  # Should be (2, 1024)\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    combined_embeddings, labels = batch\n",
    "    print(f\"Combined embeddings batch shape: {combined_embeddings.shape}\")  # Should be (batch_size, 2, 1024)\n",
    "    print(f\"Labels batch shape: {labels.shape}\")  # Should be (batch_size,)\n",
    "    break  # Stop after the first batch for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Integrate the Transformer Block\\\n",
    "We'll create a model class that:\n",
    "\n",
    "Takes the combined TCR and epitope embeddings as input.\n",
    "\n",
    "Passes them through the TransformerBlock.\n",
    "\n",
    "Flattens the output and passes it through a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TCR_Epitope_Model(nn.Module):\n",
    "    def __init__(self, embed_dim, n_heads, dropout=0.1, classifier_hidden_dim=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: Dimensionality of the input embeddings (1024 in your case).\n",
    "            n_heads: Number of attention heads in the transformer.\n",
    "            dropout: Dropout rate for regularization.\n",
    "            classifier_hidden_dim: Hidden dimension of the classifier.\n",
    "        \"\"\"\n",
    "        super(TCR_Epitope_Model, self).__init__()\n",
    "        \n",
    "        # Transformer Block\n",
    "        self.transformer_block = TransformerBlock(embed_dim, n_heads, dropout)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * embed_dim, classifier_hidden_dim),  # Input: flattened transformer output\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(classifier_hidden_dim, 1)  # Output: binary prediction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 2, embed_dim).\n",
    "        \n",
    "        Returns:\n",
    "            logits: Output tensor of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        # Permute input to (seq_len, batch_size, embed_dim) for the transformer\n",
    "        x = x.permute(1, 0, 2)  # Shape: (2, batch_size, embed_dim)\n",
    "        \n",
    "        # Pass through the transformer block\n",
    "        x = self.transformer_block(x)  # Shape: (2, batch_size, embed_dim)\n",
    "        \n",
    "        # Permute back to (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(1, 0, 2)  # Shape: (batch_size, 2, embed_dim)\n",
    "        \n",
    "        # Flatten the output\n",
    "        x = x.reshape(x.size(0), -1)  # Shape: (batch_size, 2 * embed_dim)\n",
    "        \n",
    "        # Pass through the classifier\n",
    "        logits = self.classifier(x)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Test the Model \\\n",
    "Let's test the model with a batch of data to ensure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# # Initialize the model\n",
    "# embed_dim = 1024  # Dimensionality of TCR and epitope embeddings\n",
    "# n_heads = 4       # Number of attention heads\n",
    "# model = TCR_Epitope_Model(embed_dim, n_heads)\n",
    "\n",
    "# # Get a batch of data from the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     combined_embeddings, labels = batch\n",
    "#     break  # Stop after the first batch\n",
    "\n",
    "# # Pass the batch through the model\n",
    "# logits = model(combined_embeddings)\n",
    "# print(f\"Logits shape: {logits.shape}\")  # Should be (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we forgot to use GPU. Then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: Tesla T4\n",
      "Model is on: cuda:0\n",
      "Data is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU.\")\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "model = model.to(device)\n",
    "\n",
    "# Move Data to GPU\n",
    "\n",
    "for batch in dataloader:\n",
    "    combined_embeddings, labels = batch\n",
    "    \n",
    "    # Move data to the GPU (if available)\n",
    "    combined_embeddings = combined_embeddings.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Rest of the training loop...\n",
    "\n",
    "# Verify GPU Usage\n",
    "\n",
    "# Check model device\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "\n",
    "# Check data device\n",
    "print(f\"Data is on: {combined_embeddings.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Add a Training Loop\\\n",
    "Now, let's add a simple training loop to train the model. We'll use binary cross-entropy loss and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.30530472857386276\n",
      "Epoch 2/5, Loss: 0.1719683983865046\n",
      "Epoch 3/5, Loss: 0.157329112976129\n",
      "Epoch 4/5, Loss: 0.14955465956043631\n",
      "Epoch 5/5, Loss: 0.14537664496026595\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = TCR_Epitope_Model(embed_dim, n_heads).to(device)  # Move model to GPU\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        \n",
    "        # Move data to the GPU (if available)\n",
    "        combined_embeddings = combined_embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(combined_embeddings).squeeze()  # Shape: (batch_size,)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Prepare a Validation Set\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% training\n",
    "val_size = len(dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 2: Evaluation Function\\\n",
    "We'll write a function to evaluate the model on the validation set. This function will:\n",
    "\n",
    "Switch the model to evaluation mode.\n",
    "\n",
    "Disable gradient computation.\n",
    "\n",
    "Compute predictions and metrics like accuracy, ROC-AUC, and precision-recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in dataloader:\n",
    "            combined_embeddings, labels = batch\n",
    "            \n",
    "            # Move data to the GPU (if available)\n",
    "            combined_embeddings = combined_embeddings.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(combined_embeddings).squeeze()\n",
    "            predictions = torch.sigmoid(logits)  # Convert logits to probabilities\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions > 0.5)  # Threshold at 0.5\n",
    "    roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions > 0.5, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions > 0.5, zero_division=0)\n",
    "    \n",
    "    return accuracy, roc_auc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for batch in train_dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        \n",
    "        # Move data to the GPU (if available)\n",
    "        combined_embeddings = combined_embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(combined_embeddings).squeeze()\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print training loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_dataloader)}\")\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    accuracy, roc_auc, precision, recall = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Metrics - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"tcr_epitope_model.pth\")\n",
    "\n",
    "# To load the model later:\n",
    "\n",
    "# Load the model\n",
    "model = TCR_Epitope_Model(embed_dim, n_heads).to(device)\n",
    "model.load_state_dict(torch.load(\"tcr_epitope_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with hyperparameter tuning, test set evaluation, and visualizations for your Multihead Attention Model. We'll break this down into clear steps. \n",
    "\n",
    "Step 1: Hyperparameter Tuning \\\n",
    "Hyperparameter tuning involves finding the best set of hyperparameters (e.g., learning rate, number of attention heads, dropout rate) for your model. We'll use a simple grid search approach.\n",
    "\n",
    "Key Hyperparameters to Tune:\n",
    "\n",
    "Learning Rate: Controls the step size during optimization.\n",
    "\n",
    "Number of Attention Heads: Determines how many parallel attention mechanisms to use.\n",
    "\n",
    "Dropout Rate: Regularization to prevent overfitting.\n",
    "\n",
    "Hidden Dimension of the Classifier: Size of the hidden layer in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define hyperparameter grid\n",
    "learning_rates = [1e-3, 1e-4]\n",
    "n_heads_list = [2, 4, 8]\n",
    "dropout_rates = [0.1, 0.2]\n",
    "classifier_hidden_dims = [64, 128]\n",
    "\n",
    "# Iterate over all combinations\n",
    "best_roc_auc = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for lr, n_heads, dropout, hidden_dim in product(learning_rates, n_heads_list, dropout_rates, classifier_hidden_dims):\n",
    "    print(f\"Testing: lr={lr}, n_heads={n_heads}, dropout={dropout}, hidden_dim={hidden_dim}\")\n",
    "    \n",
    "    # Initialize model with current hyperparameters\n",
    "    model = TCR_Epitope_Model(embed_dim=1024, n_heads=n_heads, dropout=dropout, classifier_hidden_dim=hidden_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(5):  # Short training for hyperparameter tuning\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            combined_embeddings, labels = batch\n",
    "            combined_embeddings, labels = combined_embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(combined_embeddings).squeeze()\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    accuracy, roc_auc, precision, recall = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Metrics - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Track the best hyperparameters\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        best_hyperparams = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"n_heads\": n_heads,\n",
    "            \"dropout\": dropout,\n",
    "            \"classifier_hidden_dim\": hidden_dim\n",
    "        }\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}, Best ROC-AUC: {best_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Test Set Evaluation \\\n",
    "Once you've identified the best hyperparameters, evaluate the model on the test set.\n",
    "\n",
    "Load the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test embeddings (assuming Scenario B: shared embeddings)\n",
    "test_tcr_embeddings = all_tcr_embeddings[test_tcr_indices]\n",
    "test_epitope_embeddings = all_epitope_embeddings[test_epitope_indices]\n",
    "\n",
    "# Create test dataset and DataLoader\n",
    "test_dataset = TCR_Epitope_Dataset(test_tcr_embeddings, test_epitope_embeddings, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the best hyperparameters\n",
    "best_model = TCR_Epitope_Model(\n",
    "    embed_dim=1024,\n",
    "    n_heads=best_hyperparams[\"n_heads\"],\n",
    "    dropout=best_hyperparams[\"dropout\"],\n",
    "    classifier_hidden_dim=best_hyperparams[\"classifier_hidden_dim\"]\n",
    ").to(device)\n",
    "\n",
    "# Load the trained weights (if you saved the model)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy, test_roc_auc, test_precision, test_recall = evaluate(best_model, test_dataloader, device)\n",
    "print(f\"Test Metrics - Accuracy: {test_accuracy:.4f}, ROC-AUC: {test_roc_auc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Visualizations \\\n",
    "Visualizations help you understand the model's performance. We'll create:\n",
    "\n",
    "ROC Curve: To visualize the trade-off between true positive rate (TPR) and false positive rate (FPR).\n",
    "\n",
    "Precision-Recall Curve: To visualize the trade-off between precision and recall.\n",
    "\n",
    "Confusion Matrix: To show the distribution of predictions.\n",
    "\n",
    "ROC Curve:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions and labels\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        combined_embeddings, labels = combined_embeddings.to(device), labels.to(device)\n",
    "        \n",
    "        logits = best_model(combined_embeddings).squeeze()\n",
    "        predictions = torch.sigmoid(logits)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(all_labels, all_predictions)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "binary_predictions = (np.array(all_predictions) > 0.5).astype(int)\n",
    "cm = confusion_matrix(all_labels, binary_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Binding', 'Binding'], yticklabels=['Not Binding', 'Binding'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

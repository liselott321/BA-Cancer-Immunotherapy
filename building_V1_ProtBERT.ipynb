{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short inspection in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30452/2935229279.py:8: DtypeWarning: Columns (1,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset head:\n",
      "   TCR_name\\tTRAV\\tTRAJ\\tTRA_CDR3\\tTRBV\\tTRBJ\\tTRB_CDR3\\tTRB_leader\\tTRAC\\tTRBC\\tLinker\\tLink_order\\tTRA_5_prime_seq\\tTRA_3_prime_seq\\tTRB_5_prime_seq\\tTRB_3_prime_seq\\tEpitope\\tMHC\\tMHC class  \\\n",
      "0                                                NaN                                                                                                                                               \n",
      "1                                                NaN                                                                                                                                               \n",
      "2                                                NaN                                                                                                                                               \n",
      "3                                                NaN                                                                                                                                               \n",
      "4                                                NaN                                                                                                                                               \n",
      "\n",
      "  TCR_name         TRBV        TRBJ            TRB_CDR3 TRBC    Epitope  \\\n",
      "0      257  TRBV20-1*01  TRBJ2-5*01  CSARIWPYPAGGEETQYF  NaN  KLGGALQAK   \n",
      "1      358    TRBV28*01  TRBJ2-1*01     CASSKGLAGLDEQFF  NaN   RAKFKQLL   \n",
      "2      382   TRBV6-6*01  TRBJ2-5*01     CATQTPDSRRETQYF  NaN  KLGGALQAK   \n",
      "3      393  TRBV20-1*01  TRBJ1-2*01     CSARDLDSLTNGYTF  NaN  KLGGALQAK   \n",
      "4      396  TRBV10-2*01  TRBJ2-7*01       CASSEDREDEQYF  NaN  KLGGALQAK   \n",
      "\n",
      "           MHC  Binding  task  \n",
      "0  HLA-A*03:01        1   NaN  \n",
      "1  HLA-B*08:01        1   NaN  \n",
      "2  HLA-A*03:01        1   NaN  \n",
      "3  HLA-A*03:01        1   NaN  \n",
      "4  HLA-A*03:01        1   NaN  \n",
      "Train dataset length: 319226\n",
      "\n",
      "Validation dataset head:\n",
      "   TCR_name\\tTRAV\\tTRAJ\\tTRA_CDR3\\tTRBV\\tTRBJ\\tTRB_CDR3\\tTRB_leader\\tTRAC\\tTRBC\\tLinker\\tLink_order\\tTRA_5_prime_seq\\tTRA_3_prime_seq\\tTRB_5_prime_seq\\tTRB_3_prime_seq\\tEpitope\\tMHC\\tMHC class  \\\n",
      "0                                                NaN                                                                                                                                               \n",
      "1                                                NaN                                                                                                                                               \n",
      "2                                                NaN                                                                                                                                               \n",
      "3                                                NaN                                                                                                                                               \n",
      "4                                                NaN                                                                                                                                               \n",
      "\n",
      "  TCR_name         TRBV        TRBJ         TRB_CDR3 TRBC  \\\n",
      "0    27366      TRBV7-8     TRBJ2-7    CASSSGGVYEQYF  NaN   \n",
      "1   146698  TRBV11-3*01  TRBJ1-3*01    CASSGMTRNTIYF  NaN   \n",
      "2    39969     TRBV11-2     TRBJ1-1   CASSEGQGNTEAFF  NaN   \n",
      "3   120250      TRBV6-5     TRBJ2-7  CASRSVGTRSYEQYF  NaN   \n",
      "4   120261     TRBV12-3     TRBJ2-1   CASRTAGVYNEQFF  NaN   \n",
      "\n",
      "                     Epitope          MHC  Binding  task  \n",
      "0                  LLWNGPMAV  HLA-A*02:01        1  TPP1  \n",
      "1                  GLCTLVAML  HLA-A*02:01        1  TPP1  \n",
      "2  MIELSLIDFYLCFLAFLLFLVLIML          NaN        1  TPP1  \n",
      "3                 TPRVTGGGAM  HLA-B*07:02        1  TPP1  \n",
      "4                 TPRVTGGGAM  HLA-B*07:02        1  TPP1  \n",
      "Validation dataset length: 239418\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "train_path = '../../data/splitted_datasets/allele/beta/train.tsv'\n",
    "valid_path = '../../data/splitted_datasets/allele/beta/validation.tsv'\n",
    "\n",
    "# Load the TSV files\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "valid_df = pd.read_csv(valid_path, sep='\\t')\n",
    "\n",
    "# Print the head (first few rows) and length (number of rows) of both datasets\n",
    "print(\"Train dataset head:\")\n",
    "print(train_df.head())  # First few rows of the training set\n",
    "print(f\"Train dataset length: {len(train_df)}\")\n",
    "\n",
    "print(\"\\nValidation dataset head:\")\n",
    "print(valid_df.head())  # First few rows of the validation set\n",
    "print(f\"Validation dataset length: {len(valid_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigations on ProtBERT-Embeddings in oder to get shape, type, etc., and be able to use them in the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the NPZ file: 1896\n",
      "\n",
      "Key: NLTTRTQL\n",
      "Shape: (8, 1024)\n",
      "Size: 8192\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.13486663  0.16832928  0.01105008 -0.2017876   0.21350099]\n",
      " [ 0.06380487  0.13675283  0.00786234 -0.12408309  0.31762993]\n",
      " [ 0.01229951  0.05960181  0.00698517 -0.0671403   0.08832411]\n",
      " [ 0.03610628  0.0980993   0.03087564 -0.11637626  0.03888167]\n",
      " [ 0.04467435  0.12075185  0.01568509 -0.10579667  0.06191917]]\n",
      "\n",
      "Key: FIYIFHTL\n",
      "Shape: (8, 1024)\n",
      "Size: 8192\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.10352622  0.19366597  0.01785575 -0.14839908  0.25590894]\n",
      " [-0.05904485  0.1726287   0.08648816  0.00153423  0.19045785]\n",
      " [-0.03943206  0.14551184  0.07295718  0.01637407  0.07709593]\n",
      " [-0.04497753  0.11167102 -0.02338432  0.08326313  0.1050052 ]\n",
      " [-0.02016015  0.17720129  0.05871242  0.01146071  0.08313055]]\n",
      "\n",
      "Key: YMHHMELPT\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.06514921  0.11687686  0.04630813 -0.13314888  0.2626437 ]\n",
      " [ 0.03239926  0.09270856 -0.06613344  0.10825594  0.22238302]\n",
      " [-0.04459083  0.11944033  0.08202285  0.00903853  0.20343044]\n",
      " [-0.06591333  0.04584923 -0.0100627   0.03922262  0.07404124]\n",
      " [-0.06201258  0.0835928  -0.00328284  0.02340558  0.08391251]]\n",
      "\n",
      "Key: ILLDWAANI\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.1645789   0.16454928  0.05097169 -0.18367876  0.22337942]\n",
      " [ 0.05207512  0.18722653  0.02419805 -0.058014    0.17848566]\n",
      " [-0.09758498 -0.02297855 -0.02284254  0.11435525  0.06869881]\n",
      " [-0.05901216 -0.02084499  0.03752796  0.11448745  0.06468341]\n",
      " [ 0.01347261  0.01105556  0.01085016  0.00422142  0.00759499]]\n",
      "\n",
      "Key: SMWALVISV\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.13382603  0.17833568  0.05681703 -0.16807695  0.28101236]\n",
      " [ 0.0540608   0.02565792  0.01853698 -0.09408475  0.14658062]\n",
      " [ 0.03769435  0.03907148  0.00128629 -0.04829998  0.09988906]\n",
      " [ 0.01763713 -0.01054653 -0.04083464 -0.01348473 -0.00274556]\n",
      " [ 0.07827983  0.0613616  -0.03358259 -0.11400963  0.00127117]]\n",
      "\n",
      "Key: LYALVYFLQ\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.08476291  0.20222266  0.06196603 -0.14673246  0.23006561]\n",
      " [-0.14318103  0.05591617 -0.00127477  0.11112293  0.14740887]\n",
      " [-0.06780659  0.08569615 -0.08425176  0.11367673  0.0485346 ]\n",
      " [-0.08426807  0.09359098 -0.00910662  0.06339386  0.02945401]\n",
      " [-0.17015631  0.00465459  0.00782919  0.14257677  0.07460892]]\n",
      "\n",
      "Key: WLPTGTLLV\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 7.11493343e-02  1.65525571e-01  1.26987230e-02 -1.45161450e-01\n",
      "   2.32726499e-01]\n",
      " [ 8.07066783e-02  1.16721235e-01 -3.00281271e-02  1.76357739e-02\n",
      "   1.69594646e-01]\n",
      " [-5.53761609e-02  3.14663863e-03 -4.00667004e-02  7.39174262e-02\n",
      "   6.55133873e-02]\n",
      " [ 2.84234341e-02 -9.72590316e-03 -5.74579909e-02 -3.21520418e-02\n",
      "  -1.36363000e-01]\n",
      " [ 2.73284502e-02  1.30570233e-01 -2.20451001e-02 -8.79020765e-02\n",
      "  -1.00181984e-04]]\n",
      "\n",
      "Key: YVDDVVLGA\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[-0.0024154   0.12843473  0.0225231  -0.14156406  0.28215185]\n",
      " [ 0.02715496  0.05313357 -0.09671949  0.07621586  0.05791095]\n",
      " [-0.04939542  0.0488166   0.03799681 -0.0058029  -0.05534845]\n",
      " [ 0.01083976  0.00643365 -0.03478385 -0.06003731 -0.10587035]\n",
      " [-0.01217522  0.01530864 -0.04609848 -0.05830718 -0.10603323]]\n",
      "\n",
      "Key: GTSGSPIVAR\n",
      "Shape: (10, 1024)\n",
      "Size: 10240\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.06974209  0.14879663  0.10697252 -0.17935663  0.24209325]\n",
      " [ 0.05517931 -0.03474814  0.06169648 -0.06058516  0.04527742]\n",
      " [ 0.08977984  0.03090146  0.00056062 -0.16347373  0.01186237]\n",
      " [ 0.0510754   0.01041487  0.10906803 -0.13072549  0.19618535]\n",
      " [ 0.10519237 -0.05887794  0.03077317 -0.04610283  0.01222026]]\n",
      "\n",
      "Key: LTGHMLDMY\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.09455532  0.15318629  0.05579497 -0.13188438  0.2803143 ]\n",
      " [-0.09015333  0.02826832  0.01212277  0.1419175   0.25118333]\n",
      " [-0.07790209  0.13092007  0.01606615  0.01464872  0.06838296]\n",
      " [-0.05344576  0.07159731 -0.00455313  0.05558321  0.11078076]\n",
      " [-0.09847418  0.06165167 -0.0413266   0.02965492  0.07923073]]\n",
      "Number of keys in the NPZ file: 199653\n",
      "\n",
      "Key: CASSSTASRNTGELFF\n",
      "Shape: (16, 1024)\n",
      "Size: 16384\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.07469119  0.16057323 -0.02494635 -0.12556049  0.19221778]\n",
      " [-0.00656565  0.14308369 -0.03793573 -0.1554746   0.24289103]\n",
      " [ 0.0885237   0.06751317  0.04995612 -0.15602483 -0.00942309]\n",
      " [ 0.07394025  0.0131586   0.08071905 -0.12810881  0.08166827]\n",
      " [ 0.07159891  0.01876852  0.073502   -0.12457485  0.08144016]]\n",
      "\n",
      "Key: CASSLVTGEQYF\n",
      "Shape: (12, 1024)\n",
      "Size: 12288\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.07010764  0.12251393  0.02140945 -0.16270812  0.24841776]\n",
      " [ 0.05499206  0.11281241  0.03106381 -0.078941    0.20540527]\n",
      " [ 0.05064077  0.02822007 -0.00722912 -0.09067001  0.00904552]\n",
      " [ 0.02219009 -0.00742153  0.07775165 -0.05271496  0.12367377]\n",
      " [ 0.03937658  0.01345454  0.08577791 -0.06563974  0.11149757]]\n",
      "\n",
      "Key: CASSAHRGGYGYTF\n",
      "Shape: (14, 1024)\n",
      "Size: 14336\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.0259957   0.14121705  0.02583774 -0.16263919  0.21499923]\n",
      " [ 0.06158676  0.03402864  0.04027538 -0.07507148  0.15073666]\n",
      " [ 0.06063946  0.06699179  0.06803514 -0.07316865  0.07636785]\n",
      " [ 0.03237424 -0.00231018  0.11510685 -0.02450134  0.13999277]\n",
      " [ 0.03153361  0.01758576  0.11263457 -0.02732282  0.15621635]]\n",
      "\n",
      "Key: CASSLGRTGGNIQYF\n",
      "Shape: (15, 1024)\n",
      "Size: 15360\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.09804129  0.09820717  0.02049457 -0.12856779  0.21390699]\n",
      " [ 0.08903929  0.16557583  0.01409251 -0.13702932  0.2974042 ]\n",
      " [ 0.06773366  0.0675644   0.0435829  -0.11334272  0.06439715]\n",
      " [ 0.03478089  0.01890391  0.10661771 -0.05421938  0.16203704]\n",
      " [ 0.03930545  0.04148522  0.10854344 -0.04548183  0.14797124]]\n",
      "\n",
      "Key: CSARGQEGQYISYEQYF\n",
      "Shape: (17, 1024)\n",
      "Size: 17408\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.01932946  0.1382388  -0.00449134 -0.08856098  0.19165596]\n",
      " [ 0.02416678  0.1431091   0.04314493 -0.08867458  0.27244067]\n",
      " [ 0.00480766  0.02736266  0.06795171 -0.01584252  0.16667004]\n",
      " [ 0.06505071  0.10113262 -0.01426045 -0.04396826  0.0521609 ]\n",
      " [-0.02731858  0.04183019 -0.00057096  0.03345158  0.04350732]]\n",
      "\n",
      "Key: CASSGKQGCDTEAFF\n",
      "Shape: (15, 1024)\n",
      "Size: 15360\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.03795411  0.17988847  0.01271268 -0.13178729  0.21033947]\n",
      " [ 0.06393876  0.0085198   0.00458275 -0.03879464  0.00813764]\n",
      " [ 0.07353879  0.10551791  0.03774535 -0.13709953  0.02511349]\n",
      " [ 0.04934791  0.04270718  0.10120159 -0.10174271  0.10751786]\n",
      " [ 0.04988315  0.0786605   0.0916657  -0.08712282  0.11972284]]\n",
      "\n",
      "Key: CASHQTGGRDTEAFF\n",
      "Shape: (15, 1024)\n",
      "Size: 15360\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.04551863  0.14790724 -0.02047832 -0.15338682  0.21382557]\n",
      " [ 0.07782343  0.05539408 -0.04363305 -0.04090966  0.0998164 ]\n",
      " [ 0.05377225  0.11179271  0.01632312 -0.11428415  0.06922784]\n",
      " [ 0.01825636  0.04956283  0.09200361 -0.05137397  0.17221723]\n",
      " [-0.01347755  0.04456992  0.00423876 -0.01620701  0.06052136]]\n",
      "\n",
      "Key: CSASSPRLTSNQPQHF\n",
      "Shape: (16, 1024)\n",
      "Size: 16384\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.07574212  0.10970163  0.00150833 -0.13109115  0.12338831]\n",
      " [ 0.01861601  0.09567336  0.03823717 -0.10818074  0.16575798]\n",
      " [ 0.04485331  0.01937971  0.09304145 -0.09059825  0.1102045 ]\n",
      " [ 0.0963963   0.05458871  0.04254222 -0.11261372 -0.00557708]\n",
      " [ 0.06543909  0.02160901  0.11010893 -0.08391578  0.09368671]]\n",
      "\n",
      "Key: CASSIIDGINLSYNEQFF\n",
      "Shape: (18, 1024)\n",
      "Size: 18432\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.08439212  0.14210248  0.04210078 -0.12809177  0.25006005]\n",
      " [ 0.063409    0.16236842  0.00173241 -0.0832165   0.2772287 ]\n",
      " [-0.01487497  0.01825052  0.00953387 -0.09049478  0.02372776]\n",
      " [-0.04881179 -0.00047715  0.08077581 -0.03949557  0.12681617]\n",
      " [-0.04605204  0.02459216  0.07439072 -0.08289557  0.103013  ]]\n",
      "\n",
      "Key: CASSLVGGELFF\n",
      "Shape: (12, 1024)\n",
      "Size: 12288\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 5.9192471e-02  1.5573145e-01  9.1706561e-03 -1.2763464e-01\n",
      "   2.5335079e-01]\n",
      " [-3.7754830e-02 -3.4782767e-02  1.4735702e-02 -6.7909606e-02\n",
      "   4.7309119e-02]\n",
      " [ 4.9934052e-02  1.9687060e-02 -1.8533036e-03 -8.5300505e-02\n",
      "  -1.5940756e-02]\n",
      " [ 2.9749207e-02  2.2412003e-04  7.5775057e-02 -4.1687630e-02\n",
      "   9.1509439e-02]\n",
      " [ 4.2623851e-02  3.2320082e-02  7.7929325e-02 -4.0884953e-02\n",
      "   7.5231127e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Path to the embeddings file\n",
    "paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "\n",
    "beta_all_epi_path = '../../data/embeddings/beta/allele/Epitope_beta_embeddings.npz'\n",
    "beta_all_trb_path = '../../data/embeddings/beta/allele/TRB_beta_embeddings.npz'\n",
    "paths = [paired_all_epi_path, paired_all_tra_path,paired_all_trb_path ]\n",
    "\n",
    "paths_beta = [beta_all_epi_path, beta_all_trb_path]\n",
    "for path in paths_beta:\n",
    "    # Load the NPZ file\n",
    "    data = np.load(path)\n",
    "\n",
    "    # Print available keys in the file\n",
    "    print(\"Number of keys in the NPZ file:\", len(data.files))\n",
    "\n",
    "    # Inspect the shape and size of each stored array\n",
    "    for key in data.files[:10]:\n",
    "        array = data[key]\n",
    "        print(f\"\\nKey: {key}\")\n",
    "        print(f\"Shape: {array.shape}\")\n",
    "        print(f\"Size: {array.size}\")\n",
    "        print(f\"Data Type: {array.dtype}\")\n",
    "        print(f\"Sample Data (first 5 elements):\\n{array[:5] if array.ndim == 1 else array[:5, :5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the NPZ file: 1383\n",
      "Number of keys in the NPZ file: 41519\n",
      "Number of keys in the NPZ file: 45261\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Path to the embeddings file\n",
    "paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "paths = [paired_all_epi_path, paired_all_tra_path,paired_all_trb_path ]\n",
    "for path in paths:\n",
    "    # Load the NPZ file\n",
    "    data = np.load(path)\n",
    "\n",
    "    # Print available keys in the file\n",
    "    print(\"Number of keys in the NPZ file:\", len(data.files))\n",
    "\n",
    "    # Inspect the shape and size of each stored array\n",
    "    # for key in data.files[:10]:\n",
    "    #     array = data[key]\n",
    "    #     print(f\"\\nKey: {key}\")\n",
    "    #     print(f\"Shape: {array.shape}\")\n",
    "    #     print(f\"Size: {array.size}\")\n",
    "    #     print(f\"Data Type: {array.dtype}\")\n",
    "    #     print(f\"Sample Data (first 5 elements):\\n{array[:5] if array.ndim == 1 else array[:5, :5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 41519 but got size 45261 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m padded_trb \u001b[38;5;241m=\u001b[39m pad_embeddings(trb_embeddings, max_len)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Concatenate along sequence dimension\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m padded_combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([padded_tra, padded_trb, padded_epi], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Save padded embeddings\u001b[39;00m\n\u001b[1;32m     37\u001b[0m padd_paired_all_epi_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/embeddings/paired/allele/padded_Epitope_paired_embeddings.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 41519 but got size 45261 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# raising error, because length tra != length trb.  To be solved.\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Paths to the embeddings files\n",
    "paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "\n",
    "# Load NPZ files\n",
    "epi_data = np.load(paired_all_epi_path, allow_pickle=True)\n",
    "tra_data = np.load(paired_all_tra_path, allow_pickle=True)\n",
    "trb_data = np.load(paired_all_trb_path, allow_pickle=True)\n",
    "\n",
    "# Extract embeddings\n",
    "epi_embeddings = [torch.tensor(epi_data[key]) for key in epi_data]\n",
    "tra_embeddings = [torch.tensor(tra_data[key]) for key in tra_data]\n",
    "trb_embeddings = [torch.tensor(trb_data[key]) for key in trb_data]\n",
    "\n",
    "# Find max sequence length\n",
    "max_len = max(max(e.shape[0] for e in epi_embeddings), \n",
    "              max(e.shape[0] for e in tra_embeddings), \n",
    "              max(e.shape[0] for e in trb_embeddings))\n",
    "\n",
    "# Pad sequences\n",
    "def pad_embeddings(embeddings, max_len):\n",
    "    return pad_sequence([torch.nn.functional.pad(e, (0, 0, 0, max_len - e.shape[0])) for e in embeddings], batch_first=True, padding_value=0.0)\n",
    "\n",
    "padded_epi = pad_embeddings(epi_embeddings, max_len)\n",
    "padded_tra = pad_embeddings(tra_embeddings, max_len)\n",
    "padded_trb = pad_embeddings(trb_embeddings, max_len)\n",
    "\n",
    "# Concatenate along sequence dimension\n",
    "padded_combined = torch.cat([padded_tra, padded_trb, padded_epi], dim=1)\n",
    "\n",
    "# Save padded embeddings\n",
    "padd_paired_all_epi_path = '../../data/embeddings/paired/allele/padded_Epitope_paired_embeddings.npz'\n",
    "padd_paired_all_tra_path = '../../data/embeddings/paired/allele/padded_TRA_paired_embeddings.npz'\n",
    "padd_paired_all_trb_path = '../../data/embeddings/paired/allele/padded_TRB_paired_embeddings.npz'\n",
    "padd_paired_combined_path = '../../data/embeddings/paired/allele/padded_Combined_paired_embeddings.npz'\n",
    "\n",
    "np.savez(padd_paired_all_epi_path, **{key: padded_epi[i].numpy() for i, key in enumerate(epi_data)})\n",
    "np.savez(padd_paired_all_tra_path, **{key: padded_tra[i].numpy() for i, key in enumerate(tra_data)})\n",
    "np.savez(padd_paired_all_trb_path, **{key: padded_trb[i].numpy() for i, key in enumerate(trb_data)})\n",
    "np.savez(padd_paired_combined_path, combined=padded_combined.numpy())\n",
    "\n",
    "print(\"Padded and concatenated embeddings saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beta and paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.56 GiB of which 2.75 MiB is free. Including non-PyTorch memory, this process has 14.56 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 64.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# epi_embeddings = load_embeddings_to_gpu(paired_all_epi_path)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# tra_embeddings = load_embeddings_to_gpu(paired_all_tra_path)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# trb_embeddings = load_embeddings_to_gpu(paired_all_trb_path)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m beta_epi_embeddings \u001b[38;5;241m=\u001b[39m load_embeddings_to_gpu(beta_all_epi_path)\n\u001b[0;32m---> 27\u001b[0m beta_trb_embeddings \u001b[38;5;241m=\u001b[39m load_embeddings_to_gpu(beta_all_trb_path)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Find max sequence length\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# max_len = max(max(e.shape[0] for e in epi_embeddings.values()), \u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#               max(e.shape[0] for e in tra_embeddings.values()), \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#               max(e.shape[0] for e in trb_embeddings.values()))\u001b[39;00m\n\u001b[1;32m     34\u001b[0m beta_max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(e\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m beta_epi_embeddings\u001b[38;5;241m.\u001b[39mvalues()), \n\u001b[1;32m     35\u001b[0m                     \u001b[38;5;28mmax\u001b[39m(e\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m beta_trb_embeddings\u001b[38;5;241m.\u001b[39mvalues()))\n",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m, in \u001b[0;36mload_embeddings_to_gpu\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_embeddings_to_gpu\u001b[39m(path):\n\u001b[1;32m     19\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: torch\u001b[38;5;241m.\u001b[39mtensor(data[key], device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data}\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.56 GiB of which 2.75 MiB is free. Including non-PyTorch memory, this process has 14.56 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 64.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths to embeddings files\n",
    "# paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "# paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "# paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "\n",
    "beta_all_epi_path = '../../data/embeddings/beta/allele/Epitope_beta_embeddings.npz'\n",
    "beta_all_trb_path = '../../data/embeddings/beta/allele/TRB_beta_embeddings.npz'\n",
    "\n",
    "# Load NPZ files into GPU\n",
    "def load_embeddings_to_gpu(path):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    return {key: torch.tensor(data[key], device=device) for key in data}\n",
    "\n",
    "# epi_embeddings = load_embeddings_to_gpu(paired_all_epi_path)\n",
    "# tra_embeddings = load_embeddings_to_gpu(paired_all_tra_path)\n",
    "# trb_embeddings = load_embeddings_to_gpu(paired_all_trb_path)\n",
    "\n",
    "beta_epi_embeddings = load_embeddings_to_gpu(beta_all_epi_path)\n",
    "beta_trb_embeddings = load_embeddings_to_gpu(beta_all_trb_path)\n",
    "\n",
    "# Find max sequence length\n",
    "# max_len = max(max(e.shape[0] for e in epi_embeddings.values()), \n",
    "#               max(e.shape[0] for e in tra_embeddings.values()), \n",
    "#               max(e.shape[0] for e in trb_embeddings.values()))\n",
    "\n",
    "beta_max_len = max(max(e.shape[0] for e in beta_epi_embeddings.values()), \n",
    "                    max(e.shape[0] for e in beta_trb_embeddings.values()))\n",
    "\n",
    "# Function to pad embeddings on GPU\n",
    "def pad_embeddings(embeddings, max_len):\n",
    "    return pad_sequence(\n",
    "        [torch.nn.functional.pad(e, (0, 0, 0, max_len - e.shape[0])) for e in embeddings.values()],\n",
    "        batch_first=True, padding_value=0.0\n",
    "    )\n",
    "\n",
    "# Pad embeddings (all computations on GPU)\n",
    "# padded_epi = pad_embeddings(epi_embeddings, max_len)\n",
    "# padded_tra = pad_embeddings(tra_embeddings, max_len)\n",
    "# padded_trb = pad_embeddings(trb_embeddings, max_len)\n",
    "\n",
    "padded_beta_epi = pad_embeddings(beta_epi_embeddings, beta_max_len)\n",
    "# padded_beta_trb = pad_embeddings(beta_trb_embeddings, beta_max_len)\n",
    "\n",
    "# Move back to CPU before saving\n",
    "# padded_epi = padded_epi.cpu().numpy()\n",
    "# padded_tra = padded_tra.cpu().numpy()\n",
    "# padded_trb = padded_trb.cpu().numpy()\n",
    "\n",
    "padded_beta_epi = padded_beta_epi.cpu().numpy()\n",
    "# padded_beta_trb = padded_beta_trb.cpu().numpy()\n",
    "\n",
    "# Save padded embeddings\n",
    "# padd_paired_all_epi_path = '../../data/embeddings/paired/allele/padded_Epitope_paired_embeddings.npz'\n",
    "# padd_paired_all_tra_path = '../../data/embeddings/paired/allele/padded_TRA_paired_embeddings.npz'\n",
    "# padd_paired_all_trb_path = '../../data/embeddings/paired/allele/padded_TRB_paired_embeddings.npz'\n",
    "\n",
    "padd_beta_all_epi_path = '../../data/embeddings/beta/allele/padded_Epitope_beta_embeddings.npz'\n",
    "# padd_beta_all_trb_path = '../../data/embeddings/beta/allele/padded_TRB_beta_embeddings.npz'\n",
    "\n",
    "# np.savez(padd_paired_all_epi_path, **{key: padded_epi[i] for i, key in enumerate(epi_embeddings)})\n",
    "# np.savez(padd_paired_all_tra_path, **{key: padded_tra[i] for i, key in enumerate(tra_embeddings)})\n",
    "# np.savez(padd_paired_all_trb_path, **{key: padded_trb[i] for i, key in enumerate(trb_embeddings)})\n",
    "\n",
    "np.savez(padd_beta_all_epi_path, **{key: padded_beta_epi[i] for i, key in enumerate(beta_epi_embeddings)})\n",
    "# np.savez(padd_beta_all_trb_path, **{key: padded_beta_trb[i] for i, key in enumerate(beta_trb_embeddings)})\n",
    "\n",
    "print(\"Padded embedding saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "## Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Baseline Transformer Block \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)  # Normalization for stability\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout to prevent overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multihead Attention with Residual Connection\n",
    "        attn_output, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))  # Add & Norm\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30452/2300908741.py:8: DtypeWarning: Columns (1,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(train_path, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the training and validation data\n",
    "train_path = '../../data/splitted_datasets/allele/beta/train.tsv'\n",
    "validation_path = '../../data/splitted_datasets/allele/beta/validation.tsv'\n",
    "\n",
    "train_data = pd.read_csv(train_path, sep='\\t')\n",
    "validation_data = pd.read_csv(validation_path, sep='\\t')\n",
    "\n",
    "# Load the embeddings\n",
    "tcr_embeddings_path = '../../data/embeddings/beta/allele/TRB_beta_embeddings.npz'\n",
    "epitope_embeddings_path = '../../data/embeddings/beta/allele/Epitope_beta_embeddings.npz'\n",
    "\n",
    "tcr_embeddings = np.load(tcr_embeddings_path, allow_pickle=True)\n",
    "epitope_embeddings = np.load(epitope_embeddings_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Padding the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_embeddings(embeddings_dict, max_length):\n",
    "    padded_embeddings = {}\n",
    "    for key, embedding in embeddings_dict.items():\n",
    "        padded_embedding = np.zeros((max_length, embedding.shape[1]))\n",
    "        padded_embedding[:embedding.shape[0], :] = embedding\n",
    "        padded_embeddings[key] = padded_embedding\n",
    "    return padded_embeddings\n",
    "\n",
    "# Determine the maximum length for TCR and Epitope embeddings\n",
    "max_tcr_length = max([embedding.shape[0] for embedding in tcr_embeddings.values()])\n",
    "max_epitope_length = max([embedding.shape[0] for embedding in epitope_embeddings.values()])\n",
    "\n",
    "# Pad the embeddings\n",
    "padded_tcr_embeddings = pad_embeddings(tcr_embeddings, max_tcr_length)\n",
    "padded_epitope_embeddings = pad_embeddings(epitope_embeddings, max_epitope_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TCR_name         TRBV        TRBJ            TRB_CDR3 TRBC    Epitope  \\\n",
    "# 0      257  TRBV20-1*01  TRBJ2-5*01  CSARIWPYPAGGEETQYF  NaN  KLGGALQAK   \n",
    "# 1      358    TRBV28*01  TRBJ2-1*01     CASSKGLAGLDEQFF  NaN   RAKFKQLL   \n",
    "# 2      382   TRBV6-6*01  TRBJ2-5*01     CATQTPDSRRETQYF  NaN  KLGGALQAK   \n",
    "# 3      393  TRBV20-1*01  TRBJ1-2*01     CSARDLDSLTNGYTF  NaN  KLGGALQAK   \n",
    "# 4      396  TRBV10-2*01  TRBJ2-7*01       CASSEDREDEQYF  NaN  KLGGALQAK   \n",
    "\n",
    "#            MHC  Binding  task  \n",
    "# 0  HLA-A*03:01        1   NaN  \n",
    "# 1  HLA-B*08:01        1   NaN  \n",
    "# 2  HLA-A*03:01        1   NaN  \n",
    "# 3  HLA-A*03:01        1   NaN  \n",
    "# 4  HLA-A*03:01        1   NaN  \n",
    "# Train dataset length: 319226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Creating the Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TCR_Epitope_Dataset(Dataset):\n",
    "    def __init__(self, data, tcr_embeddings, epitope_embeddings):\n",
    "        self.data = data\n",
    "        self.tcr_embeddings = tcr_embeddings\n",
    "        self.epitope_embeddings = epitope_embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tcr_key = row['TRB_CDR3']\n",
    "        epitope_key = row['Epitope']\n",
    "        label = row['Binding']\n",
    "        \n",
    "        tcr_embedding = self.tcr_embeddings[tcr_key]\n",
    "        epitope_embedding = self.epitope_embeddings[epitope_key]\n",
    "        \n",
    "        return tcr_embedding, epitope_embedding, label\n",
    "\n",
    "# Create the datasets\n",
    "train_dataset = TCR_Epitope_Dataset(train_data, padded_tcr_embeddings, padded_epitope_embeddings)\n",
    "validation_dataset = TCR_Epitope_Dataset(validation_data, padded_tcr_embeddings, padded_epitope_embeddings)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCR_Epitope_Transformer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_layers, max_tcr_length, max_epitope_length, dropout=0.1):\n",
    "        super(TCR_Epitope_Transformer, self).__init__()\n",
    "        \n",
    "        # TCR and Epitope embedding layers\n",
    "        self.tcr_embedding = nn.Linear(1024, embed_dim)\n",
    "        self.epitope_embedding = nn.Linear(1024, embed_dim)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        self.tcr_positional_encoding = nn.Parameter(torch.zeros(1, max_tcr_length, embed_dim))\n",
    "        self.epitope_positional_encoding = nn.Parameter(torch.zeros(1, max_epitope_length, embed_dim))\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            AttentionBlock(embed_dim, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(embed_dim, 1)\n",
    "        \n",
    "    def forward(self, tcr, epitope):\n",
    "        # Embed TCR and Epitope\n",
    "        tcr = self.tcr_embedding(tcr) + self.tcr_positional_encoding\n",
    "        epitope = self.epitope_embedding(epitope) + self.epitope_positional_encoding\n",
    "        \n",
    "        # Concatenate TCR and Epitope embeddings\n",
    "        combined = torch.cat((tcr, epitope), dim=1)\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            combined = layer(combined)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        pooled = combined.mean(dim=1)\n",
    "        \n",
    "        # Output layer\n",
    "        output = self.output_layer(pooled)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize the model\n",
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "num_layers = 4\n",
    "model = TCR_Epitope_Transformer(embed_dim, num_heads, num_layers, max_tcr_length, max_epitope_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(tcr, epitope)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mTCR_Epitope_Transformer.forward\u001b[0;34m(self, tcr, epitope)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tcr, epitope):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Embed TCR and Epitope\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     tcr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtcr_embedding(tcr) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtcr_positional_encoding\n\u001b[1;32m     24\u001b[0m     epitope \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepitope_embedding(epitope) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepitope_positional_encoding\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Concatenate TCR and Epitope embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2 # 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for tcr, epitope, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(tcr, epitope)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for tcr, epitope, labels in validation_loader:\n",
    "        outputs = model(tcr, epitope)\n",
    "        predicted = torch.sigmoid(outputs) > 0.5\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze() == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Checking if Things are Working Properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example check for shapes\n",
    "for tcr, epitope, labels in train_loader:\n",
    "    print(f'TCR shape: {tcr.shape}')\n",
    "    print(f'Epitope shape: {epitope.shape}')\n",
    "    print(f'Labels shape: {labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, n_heads, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: Dimensionality of the input embeddings.\n",
    "            n_heads: Number of attention heads.\n",
    "            dropout: Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        # Multihead Attention\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, n_heads, dropout=dropout)\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Feedforward Network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),  # Expand dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim)   # Compress back to original dimension\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (seq_len, batch_size, embed_dim).\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor of shape (seq_len, batch_size, embed_dim).\n",
    "        \"\"\"\n",
    "        # Multihead Attention\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)  # Self-attention\n",
    "        x = x + self.dropout(attn_output)              # Residual connection\n",
    "        x = self.norm1(x)                              # Layer normalization\n",
    "        \n",
    "        # Feedforward Network\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = x + self.dropout(ffn_output)               # Residual connection\n",
    "        x = self.norm2(x)                              # Layer normalization\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Testing the Updated Dataset\\\n",
    "Let's test the updated dataset to ensure the combined embeddings are in the correct shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in TCR embeddings file: ['embeddings', 'labels']\n",
      "Keys in Epitope embeddings file: ['embeddings']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the .npz files\n",
    "tcr_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz')\n",
    "epitope_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_Epitope_embeddings.npz')\n",
    "\n",
    "# Print the keys in each file\n",
    "print(\"Keys in TCR embeddings file:\", list(tcr_data.keys()))\n",
    "print(\"Keys in Epitope embeddings file:\", list(epitope_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK!!  \n",
    "\\\n",
    "Step 1: Verify the Size of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TCR embeddings: 570500\n",
      "Number of epitope embeddings: 570500\n"
     ]
    }
   ],
   "source": [
    "# Load the TCR and epitope embeddings\n",
    "tcr_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz')\n",
    "epitope_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_Epitope_embeddings.npz')\n",
    "\n",
    "tcr_embeddings = tcr_data['embeddings']  # Use the correct key\n",
    "epitope_embeddings = epitope_data['embeddings']  # Use the correct key\n",
    "\n",
    "print(f\"Number of TCR embeddings: {len(tcr_embeddings)}\")\n",
    "print(f\"Number of epitope embeddings: {len(epitope_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Ensure Labels Match the Dataset Size\\\n",
    "If you have labels, ensure the labels array has the same length as the number of TCR/epitope embeddings. If you don't have labels, we can create dummy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 570500\n"
     ]
    }
   ],
   "source": [
    "# If you have labels, load them here\n",
    "path_to_labels = '/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz'\n",
    "labels_data = np.load(path_to_labels)  # Example: Load labels from a file\n",
    "labels = labels_data['labels']\n",
    "\n",
    "# If you don't have labels, create dummy labels\n",
    "# labels = np.zeros(len(tcr_embeddings))  # Dummy labels (all zeros)\n",
    "\n",
    "print(f\"Number of labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation and test\\\n",
    "This is only a dummy splitting, since for real testing we'll use \n",
    "a separate test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% training\n",
    "val_size = len(dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Update the Dataset Class \\\n",
    "Update the TCR_Epitope_Dataset class to ensure it uses the correct indices and handles the dataset size properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCR_Epitope_Dataset(Dataset):\n",
    "    def __init__(self, tcr_embeddings, epitope_embeddings, labels=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tcr_embeddings: Array of TCR embeddings.\n",
    "            epitope_embeddings: Array of epitope embeddings.\n",
    "            labels: Optional array of labels (1 for binding, 0 for non-binding).\n",
    "        \"\"\"\n",
    "        self.tcr_embeddings = tcr_embeddings\n",
    "        self.epitope_embeddings = epitope_embeddings\n",
    "        \n",
    "        # Ensure the number of TCR and epitope embeddings match\n",
    "        assert len(self.tcr_embeddings) == len(self.epitope_embeddings), \\\n",
    "            \"Number of TCR and epitope embeddings must match!\"\n",
    "        \n",
    "        # If labels are provided, use them; otherwise, create dummy labels\n",
    "        self.labels = labels if labels is not None else np.zeros(len(self.tcr_embeddings))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tcr_embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            combined_embedding: Combined TCR and epitope embeddings of shape (2, 1024).\n",
    "            label: Binding label (1 or 0).\n",
    "        \"\"\"\n",
    "        tcr_embedding = self.tcr_embeddings[idx]\n",
    "        epitope_embedding = self.epitope_embeddings[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        tcr_embedding = torch.tensor(tcr_embedding, dtype=torch.float32)\n",
    "        epitope_embedding = torch.tensor(epitope_embedding, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # Combine TCR and epitope embeddings along the sequence dimension\n",
    "        combined_embedding = torch.stack([tcr_embedding, epitope_embedding], dim=0)  # Shape: (2, 1024)\n",
    "        \n",
    "        return combined_embedding, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Create the Dataset and DataLoader \\\n",
    "Now, create the dataset and DataLoader with the correct data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 570500\n",
      "Combined embedding shape: torch.Size([2, 1024])\n",
      "Label: 1.0\n",
      "Combined embeddings batch shape: torch.Size([32, 2, 1024])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = TCR_Epitope_Dataset(tcr_embeddings, epitope_embeddings, labels)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(f\"Number of samples: {len(dataset)}\")\n",
    "combined_embedding, label = dataset[0]  # Get the first sample\n",
    "print(f\"Combined embedding shape: {combined_embedding.shape}\")  # Should be (2, 1024)\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    combined_embeddings, labels = batch\n",
    "    print(f\"Combined embeddings batch shape: {combined_embeddings.shape}\")  # Should be (batch_size, 2, 1024)\n",
    "    print(f\"Labels batch shape: {labels.shape}\")  # Should be (batch_size,)\n",
    "    break  # Stop after the first batch for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Integrate the Transformer Block\\\n",
    "We'll create a model class that:\n",
    "\n",
    "Takes the combined TCR and epitope embeddings as input.\n",
    "\n",
    "Passes them through the TransformerBlock.\n",
    "\n",
    "Flattens the output and passes it through a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TCR_Epitope_Model(nn.Module):\n",
    "    def __init__(self, embed_dim, n_heads, dropout=0.1, classifier_hidden_dim=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: Dimensionality of the input embeddings (1024 in your case).\n",
    "            n_heads: Number of attention heads in the transformer.\n",
    "            dropout: Dropout rate for regularization.\n",
    "            classifier_hidden_dim: Hidden dimension of the classifier.\n",
    "        \"\"\"\n",
    "        super(TCR_Epitope_Model, self).__init__()\n",
    "        \n",
    "        # Transformer Block\n",
    "        self.transformer_block = TransformerBlock(embed_dim, n_heads, dropout)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * embed_dim, classifier_hidden_dim),  # Input: flattened transformer output\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(classifier_hidden_dim, 1)  # Output: binary prediction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 2, embed_dim).\n",
    "        \n",
    "        Returns:\n",
    "            logits: Output tensor of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        # Permute input to (seq_len, batch_size, embed_dim) for the transformer\n",
    "        x = x.permute(1, 0, 2)  # Shape: (2, batch_size, embed_dim)\n",
    "        \n",
    "        # Pass through the transformer block\n",
    "        x = self.transformer_block(x)  # Shape: (2, batch_size, embed_dim)\n",
    "        \n",
    "        # Permute back to (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(1, 0, 2)  # Shape: (batch_size, 2, embed_dim)\n",
    "        \n",
    "        # Flatten the output\n",
    "        x = x.reshape(x.size(0), -1)  # Shape: (batch_size, 2 * embed_dim)\n",
    "        \n",
    "        # Pass through the classifier\n",
    "        logits = self.classifier(x)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Test the Model \\\n",
    "Let's test the model with a batch of data to ensure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# # Initialize the model\n",
    "# embed_dim = 1024  # Dimensionality of TCR and epitope embeddings\n",
    "# n_heads = 4       # Number of attention heads\n",
    "# model = TCR_Epitope_Model(embed_dim, n_heads)\n",
    "\n",
    "# # Get a batch of data from the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     combined_embeddings, labels = batch\n",
    "#     break  # Stop after the first batch\n",
    "\n",
    "# # Pass the batch through the model\n",
    "# logits = model(combined_embeddings)\n",
    "# print(f\"Logits shape: {logits.shape}\")  # Should be (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we forgot to use GPU. Then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: Tesla T4\n",
      "Model is on: cuda:0\n",
      "Data is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU.\")\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "model = model.to(device)\n",
    "\n",
    "# Move Data to GPU\n",
    "\n",
    "for batch in dataloader:\n",
    "    combined_embeddings, labels = batch\n",
    "    \n",
    "    # Move data to the GPU (if available)\n",
    "    combined_embeddings = combined_embeddings.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Rest of the training loop...\n",
    "\n",
    "# Verify GPU Usage\n",
    "\n",
    "# Check model device\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "\n",
    "# Check data device\n",
    "print(f\"Data is on: {combined_embeddings.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Add a Training Loop\\\n",
    "Now, let's add a simple training loop to train the model. We'll use binary cross-entropy loss and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.30530472857386276\n",
      "Epoch 2/5, Loss: 0.1719683983865046\n",
      "Epoch 3/5, Loss: 0.157329112976129\n",
      "Epoch 4/5, Loss: 0.14955465956043631\n",
      "Epoch 5/5, Loss: 0.14537664496026595\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = TCR_Epitope_Model(embed_dim, n_heads).to(device)  # Move model to GPU\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        \n",
    "        # Move data to the GPU (if available)\n",
    "        combined_embeddings = combined_embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(combined_embeddings).squeeze()  # Shape: (batch_size,)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Prepare a Validation Set\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% training\n",
    "val_size = len(dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 2: Evaluation Function\\\n",
    "We'll write a function to evaluate the model on the validation set. This function will:\n",
    "\n",
    "Switch the model to evaluation mode.\n",
    "\n",
    "Disable gradient computation.\n",
    "\n",
    "Compute predictions and metrics like accuracy, ROC-AUC, and precision-recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in dataloader:\n",
    "            combined_embeddings, labels = batch\n",
    "            \n",
    "            # Move data to the GPU (if available)\n",
    "            combined_embeddings = combined_embeddings.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(combined_embeddings).squeeze()\n",
    "            predictions = torch.sigmoid(logits)  # Convert logits to probabilities\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions > 0.5)  # Threshold at 0.5\n",
    "    roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions > 0.5, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions > 0.5, zero_division=0)\n",
    "    \n",
    "    return accuracy, roc_auc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for batch in train_dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        \n",
    "        # Move data to the GPU (if available)\n",
    "        combined_embeddings = combined_embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(combined_embeddings).squeeze()\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print training loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_dataloader)}\")\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    accuracy, roc_auc, precision, recall = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Metrics - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"tcr_epitope_model.pth\")\n",
    "\n",
    "# To load the model later:\n",
    "\n",
    "# Load the model\n",
    "model = TCR_Epitope_Model(embed_dim, n_heads).to(device)\n",
    "model.load_state_dict(torch.load(\"tcr_epitope_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with hyperparameter tuning, test set evaluation, and visualizations for your Multihead Attention Model. We'll break this down into clear steps. \n",
    "\n",
    "Step 1: Hyperparameter Tuning \\\n",
    "Hyperparameter tuning involves finding the best set of hyperparameters (e.g., learning rate, number of attention heads, dropout rate) for your model. We'll use a simple grid search approach.\n",
    "\n",
    "Key Hyperparameters to Tune:\n",
    "\n",
    "Learning Rate: Controls the step size during optimization.\n",
    "\n",
    "Number of Attention Heads: Determines how many parallel attention mechanisms to use.\n",
    "\n",
    "Dropout Rate: Regularization to prevent overfitting.\n",
    "\n",
    "Hidden Dimension of the Classifier: Size of the hidden layer in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define hyperparameter grid\n",
    "learning_rates = [1e-3, 1e-4]\n",
    "n_heads_list = [2, 4, 8]\n",
    "dropout_rates = [0.1, 0.2]\n",
    "classifier_hidden_dims = [64, 128]\n",
    "\n",
    "# Iterate over all combinations\n",
    "best_roc_auc = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for lr, n_heads, dropout, hidden_dim in product(learning_rates, n_heads_list, dropout_rates, classifier_hidden_dims):\n",
    "    print(f\"Testing: lr={lr}, n_heads={n_heads}, dropout={dropout}, hidden_dim={hidden_dim}\")\n",
    "    \n",
    "    # Initialize model with current hyperparameters\n",
    "    model = TCR_Epitope_Model(embed_dim=1024, n_heads=n_heads, dropout=dropout, classifier_hidden_dim=hidden_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(5):  # Short training for hyperparameter tuning\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            combined_embeddings, labels = batch\n",
    "            combined_embeddings, labels = combined_embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(combined_embeddings).squeeze()\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    accuracy, roc_auc, precision, recall = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Metrics - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Track the best hyperparameters\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        best_hyperparams = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"n_heads\": n_heads,\n",
    "            \"dropout\": dropout,\n",
    "            \"classifier_hidden_dim\": hidden_dim\n",
    "        }\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}, Best ROC-AUC: {best_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Test Set Evaluation \\\n",
    "Once you've identified the best hyperparameters, evaluate the model on the test set.\n",
    "\n",
    "Load the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test embeddings (assuming Scenario B: shared embeddings)\n",
    "test_tcr_embeddings = all_tcr_embeddings[test_tcr_indices]\n",
    "test_epitope_embeddings = all_epitope_embeddings[test_epitope_indices]\n",
    "\n",
    "# Create test dataset and DataLoader\n",
    "test_dataset = TCR_Epitope_Dataset(test_tcr_embeddings, test_epitope_embeddings, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the best hyperparameters\n",
    "best_model = TCR_Epitope_Model(\n",
    "    embed_dim=1024,\n",
    "    n_heads=best_hyperparams[\"n_heads\"],\n",
    "    dropout=best_hyperparams[\"dropout\"],\n",
    "    classifier_hidden_dim=best_hyperparams[\"classifier_hidden_dim\"]\n",
    ").to(device)\n",
    "\n",
    "# Load the trained weights (if you saved the model)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy, test_roc_auc, test_precision, test_recall = evaluate(best_model, test_dataloader, device)\n",
    "print(f\"Test Metrics - Accuracy: {test_accuracy:.4f}, ROC-AUC: {test_roc_auc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Visualizations \\\n",
    "Visualizations help you understand the model's performance. We'll create:\n",
    "\n",
    "ROC Curve: To visualize the trade-off between true positive rate (TPR) and false positive rate (FPR).\n",
    "\n",
    "Precision-Recall Curve: To visualize the trade-off between precision and recall.\n",
    "\n",
    "Confusion Matrix: To show the distribution of predictions.\n",
    "\n",
    "ROC Curve:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions and labels\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        combined_embeddings, labels = combined_embeddings.to(device), labels.to(device)\n",
    "        \n",
    "        logits = best_model(combined_embeddings).squeeze()\n",
    "        predictions = torch.sigmoid(logits)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(all_labels, all_predictions)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "binary_predictions = (np.array(all_predictions) > 0.5).astype(int)\n",
    "cm = confusion_matrix(all_labels, binary_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Binding', 'Binding'], yticklabels=['Not Binding', 'Binding'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

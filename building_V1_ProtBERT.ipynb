{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short inspection in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30452/2935229279.py:8: DtypeWarning: Columns (1,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path, sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset head:\n",
      "   TCR_name\\tTRAV\\tTRAJ\\tTRA_CDR3\\tTRBV\\tTRBJ\\tTRB_CDR3\\tTRB_leader\\tTRAC\\tTRBC\\tLinker\\tLink_order\\tTRA_5_prime_seq\\tTRA_3_prime_seq\\tTRB_5_prime_seq\\tTRB_3_prime_seq\\tEpitope\\tMHC\\tMHC class  \\\n",
      "0                                                NaN                                                                                                                                               \n",
      "1                                                NaN                                                                                                                                               \n",
      "2                                                NaN                                                                                                                                               \n",
      "3                                                NaN                                                                                                                                               \n",
      "4                                                NaN                                                                                                                                               \n",
      "\n",
      "  TCR_name         TRBV        TRBJ            TRB_CDR3 TRBC    Epitope  \\\n",
      "0      257  TRBV20-1*01  TRBJ2-5*01  CSARIWPYPAGGEETQYF  NaN  KLGGALQAK   \n",
      "1      358    TRBV28*01  TRBJ2-1*01     CASSKGLAGLDEQFF  NaN   RAKFKQLL   \n",
      "2      382   TRBV6-6*01  TRBJ2-5*01     CATQTPDSRRETQYF  NaN  KLGGALQAK   \n",
      "3      393  TRBV20-1*01  TRBJ1-2*01     CSARDLDSLTNGYTF  NaN  KLGGALQAK   \n",
      "4      396  TRBV10-2*01  TRBJ2-7*01       CASSEDREDEQYF  NaN  KLGGALQAK   \n",
      "\n",
      "           MHC  Binding  task  \n",
      "0  HLA-A*03:01        1   NaN  \n",
      "1  HLA-B*08:01        1   NaN  \n",
      "2  HLA-A*03:01        1   NaN  \n",
      "3  HLA-A*03:01        1   NaN  \n",
      "4  HLA-A*03:01        1   NaN  \n",
      "Train dataset length: 319226\n",
      "\n",
      "Validation dataset head:\n",
      "   TCR_name\\tTRAV\\tTRAJ\\tTRA_CDR3\\tTRBV\\tTRBJ\\tTRB_CDR3\\tTRB_leader\\tTRAC\\tTRBC\\tLinker\\tLink_order\\tTRA_5_prime_seq\\tTRA_3_prime_seq\\tTRB_5_prime_seq\\tTRB_3_prime_seq\\tEpitope\\tMHC\\tMHC class  \\\n",
      "0                                                NaN                                                                                                                                               \n",
      "1                                                NaN                                                                                                                                               \n",
      "2                                                NaN                                                                                                                                               \n",
      "3                                                NaN                                                                                                                                               \n",
      "4                                                NaN                                                                                                                                               \n",
      "\n",
      "  TCR_name         TRBV        TRBJ         TRB_CDR3 TRBC  \\\n",
      "0    27366      TRBV7-8     TRBJ2-7    CASSSGGVYEQYF  NaN   \n",
      "1   146698  TRBV11-3*01  TRBJ1-3*01    CASSGMTRNTIYF  NaN   \n",
      "2    39969     TRBV11-2     TRBJ1-1   CASSEGQGNTEAFF  NaN   \n",
      "3   120250      TRBV6-5     TRBJ2-7  CASRSVGTRSYEQYF  NaN   \n",
      "4   120261     TRBV12-3     TRBJ2-1   CASRTAGVYNEQFF  NaN   \n",
      "\n",
      "                     Epitope          MHC  Binding  task  \n",
      "0                  LLWNGPMAV  HLA-A*02:01        1  TPP1  \n",
      "1                  GLCTLVAML  HLA-A*02:01        1  TPP1  \n",
      "2  MIELSLIDFYLCFLAFLLFLVLIML          NaN        1  TPP1  \n",
      "3                 TPRVTGGGAM  HLA-B*07:02        1  TPP1  \n",
      "4                 TPRVTGGGAM  HLA-B*07:02        1  TPP1  \n",
      "Validation dataset length: 239418\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "train_path = '../../data/splitted_datasets/allele/beta/train.tsv'\n",
    "valid_path = '../../data/splitted_datasets/allele/beta/validation.tsv'\n",
    "\n",
    "# Load the TSV files\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "valid_df = pd.read_csv(valid_path, sep='\\t')\n",
    "\n",
    "# Print the head (first few rows) and length (number of rows) of both datasets\n",
    "print(\"Train dataset head:\")\n",
    "print(train_df.head())  # First few rows of the training set\n",
    "print(f\"Train dataset length: {len(train_df)}\")\n",
    "\n",
    "print(\"\\nValidation dataset head:\")\n",
    "print(valid_df.head())  # First few rows of the validation set\n",
    "print(f\"Validation dataset length: {len(valid_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65930/1833262170.py:9: DtypeWarning: Columns (1,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path, sep='\\t')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File paths\n",
    "train_path = '../../data/splitted_datasets/allele/beta/train.tsv'\n",
    "valid_path = '../../data/splitted_datasets/allele/beta/validation.tsv'\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "valid_df = pd.read_csv(valid_path, sep='\\t')\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([train_df, valid_df], ignore_index=True)\n",
    "\n",
    "# Ensure the columns exist\n",
    "if 'TRB_CDR3' not in data.columns or 'Epitope' not in data.columns:\n",
    "    raise ValueError(\"Columns 'TRB_CDR3' and 'Epitope' must exist in the dataset\")\n",
    "\n",
    "# Compute lengths\n",
    "data['tcr_length'] = data['TRB_CDR3'].astype(str).apply(len)\n",
    "data['epitope_length'] = data['Epitope'].astype(str).apply(len)\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data['tcr_length'], bins=20, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('TCR Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('TCR Length Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['epitope_length'], bins=20, color='green', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Epitope Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Epitope Length Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigations on ProtBERT-Embeddings in oder to get shape, type, etc., and be able to use them in the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the NPZ file: 1896\n",
      "\n",
      "Key: NLTTRTQL\n",
      "Shape: (8, 1024)\n",
      "Size: 8192\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.13486663  0.16832928  0.01105008 -0.2017876   0.21350099]\n",
      " [ 0.06380487  0.13675283  0.00786234 -0.12408309  0.31762993]\n",
      " [ 0.01229951  0.05960181  0.00698517 -0.0671403   0.08832411]\n",
      " [ 0.03610628  0.0980993   0.03087564 -0.11637626  0.03888167]\n",
      " [ 0.04467435  0.12075185  0.01568509 -0.10579667  0.06191917]]\n",
      "\n",
      "Key: FIYIFHTL\n",
      "Shape: (8, 1024)\n",
      "Size: 8192\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.10352622  0.19366597  0.01785575 -0.14839908  0.25590894]\n",
      " [-0.05904485  0.1726287   0.08648816  0.00153423  0.19045785]\n",
      " [-0.03943206  0.14551184  0.07295718  0.01637407  0.07709593]\n",
      " [-0.04497753  0.11167102 -0.02338432  0.08326313  0.1050052 ]\n",
      " [-0.02016015  0.17720129  0.05871242  0.01146071  0.08313055]]\n",
      "\n",
      "Key: YMHHMELPT\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.06514921  0.11687686  0.04630813 -0.13314888  0.2626437 ]\n",
      " [ 0.03239926  0.09270856 -0.06613344  0.10825594  0.22238302]\n",
      " [-0.04459083  0.11944033  0.08202285  0.00903853  0.20343044]\n",
      " [-0.06591333  0.04584923 -0.0100627   0.03922262  0.07404124]\n",
      " [-0.06201258  0.0835928  -0.00328284  0.02340558  0.08391251]]\n",
      "\n",
      "Key: ILLDWAANI\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.1645789   0.16454928  0.05097169 -0.18367876  0.22337942]\n",
      " [ 0.05207512  0.18722653  0.02419805 -0.058014    0.17848566]\n",
      " [-0.09758498 -0.02297855 -0.02284254  0.11435525  0.06869881]\n",
      " [-0.05901216 -0.02084499  0.03752796  0.11448745  0.06468341]\n",
      " [ 0.01347261  0.01105556  0.01085016  0.00422142  0.00759499]]\n",
      "\n",
      "Key: SMWALVISV\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.13382603  0.17833568  0.05681703 -0.16807695  0.28101236]\n",
      " [ 0.0540608   0.02565792  0.01853698 -0.09408475  0.14658062]\n",
      " [ 0.03769435  0.03907148  0.00128629 -0.04829998  0.09988906]\n",
      " [ 0.01763713 -0.01054653 -0.04083464 -0.01348473 -0.00274556]\n",
      " [ 0.07827983  0.0613616  -0.03358259 -0.11400963  0.00127117]]\n",
      "\n",
      "Key: LYALVYFLQ\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.08476291  0.20222266  0.06196603 -0.14673246  0.23006561]\n",
      " [-0.14318103  0.05591617 -0.00127477  0.11112293  0.14740887]\n",
      " [-0.06780659  0.08569615 -0.08425176  0.11367673  0.0485346 ]\n",
      " [-0.08426807  0.09359098 -0.00910662  0.06339386  0.02945401]\n",
      " [-0.17015631  0.00465459  0.00782919  0.14257677  0.07460892]]\n",
      "\n",
      "Key: WLPTGTLLV\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 7.11493343e-02  1.65525571e-01  1.26987230e-02 -1.45161450e-01\n",
      "   2.32726499e-01]\n",
      " [ 8.07066783e-02  1.16721235e-01 -3.00281271e-02  1.76357739e-02\n",
      "   1.69594646e-01]\n",
      " [-5.53761609e-02  3.14663863e-03 -4.00667004e-02  7.39174262e-02\n",
      "   6.55133873e-02]\n",
      " [ 2.84234341e-02 -9.72590316e-03 -5.74579909e-02 -3.21520418e-02\n",
      "  -1.36363000e-01]\n",
      " [ 2.73284502e-02  1.30570233e-01 -2.20451001e-02 -8.79020765e-02\n",
      "  -1.00181984e-04]]\n",
      "\n",
      "Key: YVDDVVLGA\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[-0.0024154   0.12843473  0.0225231  -0.14156406  0.28215185]\n",
      " [ 0.02715496  0.05313357 -0.09671949  0.07621586  0.05791095]\n",
      " [-0.04939542  0.0488166   0.03799681 -0.0058029  -0.05534845]\n",
      " [ 0.01083976  0.00643365 -0.03478385 -0.06003731 -0.10587035]\n",
      " [-0.01217522  0.01530864 -0.04609848 -0.05830718 -0.10603323]]\n",
      "\n",
      "Key: GTSGSPIVAR\n",
      "Shape: (10, 1024)\n",
      "Size: 10240\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.06974209  0.14879663  0.10697252 -0.17935663  0.24209325]\n",
      " [ 0.05517931 -0.03474814  0.06169648 -0.06058516  0.04527742]\n",
      " [ 0.08977984  0.03090146  0.00056062 -0.16347373  0.01186237]\n",
      " [ 0.0510754   0.01041487  0.10906803 -0.13072549  0.19618535]\n",
      " [ 0.10519237 -0.05887794  0.03077317 -0.04610283  0.01222026]]\n",
      "\n",
      "Key: LTGHMLDMY\n",
      "Shape: (9, 1024)\n",
      "Size: 9216\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.09455532  0.15318629  0.05579497 -0.13188438  0.2803143 ]\n",
      " [-0.09015333  0.02826832  0.01212277  0.1419175   0.25118333]\n",
      " [-0.07790209  0.13092007  0.01606615  0.01464872  0.06838296]\n",
      " [-0.05344576  0.07159731 -0.00455313  0.05558321  0.11078076]\n",
      " [-0.09847418  0.06165167 -0.0413266   0.02965492  0.07923073]]\n",
      "Number of keys in the NPZ file: 199653\n",
      "\n",
      "Key: CASSSTASRNTGELFF\n",
      "Shape: (16, 1024)\n",
      "Size: 16384\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.07469119  0.16057323 -0.02494635 -0.12556049  0.19221778]\n",
      " [-0.00656565  0.14308369 -0.03793573 -0.1554746   0.24289103]\n",
      " [ 0.0885237   0.06751317  0.04995612 -0.15602483 -0.00942309]\n",
      " [ 0.07394025  0.0131586   0.08071905 -0.12810881  0.08166827]\n",
      " [ 0.07159891  0.01876852  0.073502   -0.12457485  0.08144016]]\n",
      "\n",
      "Key: CASSLVTGEQYF\n",
      "Shape: (12, 1024)\n",
      "Size: 12288\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.07010764  0.12251393  0.02140945 -0.16270812  0.24841776]\n",
      " [ 0.05499206  0.11281241  0.03106381 -0.078941    0.20540527]\n",
      " [ 0.05064077  0.02822007 -0.00722912 -0.09067001  0.00904552]\n",
      " [ 0.02219009 -0.00742153  0.07775165 -0.05271496  0.12367377]\n",
      " [ 0.03937658  0.01345454  0.08577791 -0.06563974  0.11149757]]\n",
      "\n",
      "Key: CASSAHRGGYGYTF\n",
      "Shape: (14, 1024)\n",
      "Size: 14336\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.0259957   0.14121705  0.02583774 -0.16263919  0.21499923]\n",
      " [ 0.06158676  0.03402864  0.04027538 -0.07507148  0.15073666]\n",
      " [ 0.06063946  0.06699179  0.06803514 -0.07316865  0.07636785]\n",
      " [ 0.03237424 -0.00231018  0.11510685 -0.02450134  0.13999277]\n",
      " [ 0.03153361  0.01758576  0.11263457 -0.02732282  0.15621635]]\n",
      "\n",
      "Key: CASSLGRTGGNIQYF\n",
      "Shape: (15, 1024)\n",
      "Size: 15360\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.09804129  0.09820717  0.02049457 -0.12856779  0.21390699]\n",
      " [ 0.08903929  0.16557583  0.01409251 -0.13702932  0.2974042 ]\n",
      " [ 0.06773366  0.0675644   0.0435829  -0.11334272  0.06439715]\n",
      " [ 0.03478089  0.01890391  0.10661771 -0.05421938  0.16203704]\n",
      " [ 0.03930545  0.04148522  0.10854344 -0.04548183  0.14797124]]\n",
      "\n",
      "Key: CSARGQEGQYISYEQYF\n",
      "Shape: (17, 1024)\n",
      "Size: 17408\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.01932946  0.1382388  -0.00449134 -0.08856098  0.19165596]\n",
      " [ 0.02416678  0.1431091   0.04314493 -0.08867458  0.27244067]\n",
      " [ 0.00480766  0.02736266  0.06795171 -0.01584252  0.16667004]\n",
      " [ 0.06505071  0.10113262 -0.01426045 -0.04396826  0.0521609 ]\n",
      " [-0.02731858  0.04183019 -0.00057096  0.03345158  0.04350732]]\n",
      "\n",
      "Key: CASSGKQGCDTEAFF\n",
      "Shape: (15, 1024)\n",
      "Size: 15360\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.03795411  0.17988847  0.01271268 -0.13178729  0.21033947]\n",
      " [ 0.06393876  0.0085198   0.00458275 -0.03879464  0.00813764]\n",
      " [ 0.07353879  0.10551791  0.03774535 -0.13709953  0.02511349]\n",
      " [ 0.04934791  0.04270718  0.10120159 -0.10174271  0.10751786]\n",
      " [ 0.04988315  0.0786605   0.0916657  -0.08712282  0.11972284]]\n",
      "\n",
      "Key: CASHQTGGRDTEAFF\n",
      "Shape: (15, 1024)\n",
      "Size: 15360\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.04551863  0.14790724 -0.02047832 -0.15338682  0.21382557]\n",
      " [ 0.07782343  0.05539408 -0.04363305 -0.04090966  0.0998164 ]\n",
      " [ 0.05377225  0.11179271  0.01632312 -0.11428415  0.06922784]\n",
      " [ 0.01825636  0.04956283  0.09200361 -0.05137397  0.17221723]\n",
      " [-0.01347755  0.04456992  0.00423876 -0.01620701  0.06052136]]\n",
      "\n",
      "Key: CSASSPRLTSNQPQHF\n",
      "Shape: (16, 1024)\n",
      "Size: 16384\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.07574212  0.10970163  0.00150833 -0.13109115  0.12338831]\n",
      " [ 0.01861601  0.09567336  0.03823717 -0.10818074  0.16575798]\n",
      " [ 0.04485331  0.01937971  0.09304145 -0.09059825  0.1102045 ]\n",
      " [ 0.0963963   0.05458871  0.04254222 -0.11261372 -0.00557708]\n",
      " [ 0.06543909  0.02160901  0.11010893 -0.08391578  0.09368671]]\n",
      "\n",
      "Key: CASSIIDGINLSYNEQFF\n",
      "Shape: (18, 1024)\n",
      "Size: 18432\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 0.08439212  0.14210248  0.04210078 -0.12809177  0.25006005]\n",
      " [ 0.063409    0.16236842  0.00173241 -0.0832165   0.2772287 ]\n",
      " [-0.01487497  0.01825052  0.00953387 -0.09049478  0.02372776]\n",
      " [-0.04881179 -0.00047715  0.08077581 -0.03949557  0.12681617]\n",
      " [-0.04605204  0.02459216  0.07439072 -0.08289557  0.103013  ]]\n",
      "\n",
      "Key: CASSLVGGELFF\n",
      "Shape: (12, 1024)\n",
      "Size: 12288\n",
      "Data Type: float32\n",
      "Sample Data (first 5 elements):\n",
      "[[ 5.9192471e-02  1.5573145e-01  9.1706561e-03 -1.2763464e-01\n",
      "   2.5335079e-01]\n",
      " [-3.7754830e-02 -3.4782767e-02  1.4735702e-02 -6.7909606e-02\n",
      "   4.7309119e-02]\n",
      " [ 4.9934052e-02  1.9687060e-02 -1.8533036e-03 -8.5300505e-02\n",
      "  -1.5940756e-02]\n",
      " [ 2.9749207e-02  2.2412003e-04  7.5775057e-02 -4.1687630e-02\n",
      "   9.1509439e-02]\n",
      " [ 4.2623851e-02  3.2320082e-02  7.7929325e-02 -4.0884953e-02\n",
      "   7.5231127e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Path to the embeddings file\n",
    "paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "\n",
    "beta_all_epi_path = '../../data/embeddings/beta/allele/Epitope_beta_embeddings.npz'\n",
    "beta_all_trb_path = '../../data/embeddings/beta/allele/TRB_beta_embeddings.npz'\n",
    "paths = [paired_all_epi_path, paired_all_tra_path,paired_all_trb_path ]\n",
    "\n",
    "paths_beta = [beta_all_epi_path, beta_all_trb_path]\n",
    "for path in paths_beta:\n",
    "    # Load the NPZ file\n",
    "    data = np.load(path)\n",
    "\n",
    "    # Print available keys in the file\n",
    "    print(\"Number of keys in the NPZ file:\", len(data.files))\n",
    "\n",
    "    # Inspect the shape and size of each stored array\n",
    "    for key in data.files[:10]:\n",
    "        array = data[key]\n",
    "        print(f\"\\nKey: {key}\")\n",
    "        print(f\"Shape: {array.shape}\")\n",
    "        print(f\"Size: {array.size}\")\n",
    "        print(f\"Data Type: {array.dtype}\")\n",
    "        print(f\"Sample Data (first 5 elements):\\n{array[:5] if array.ndim == 1 else array[:5, :5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the NPZ file: 1383\n",
      "Number of keys in the NPZ file: 41519\n",
      "Number of keys in the NPZ file: 45261\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Path to the embeddings file\n",
    "paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "paths = [paired_all_epi_path, paired_all_tra_path,paired_all_trb_path ]\n",
    "for path in paths:\n",
    "    # Load the NPZ file\n",
    "    data = np.load(path)\n",
    "\n",
    "    # Print available keys in the file\n",
    "    print(\"Number of keys in the NPZ file:\", len(data.files))\n",
    "\n",
    "    # Inspect the shape and size of each stored array\n",
    "    # for key in data.files[:10]:\n",
    "    #     array = data[key]\n",
    "    #     print(f\"\\nKey: {key}\")\n",
    "    #     print(f\"Shape: {array.shape}\")\n",
    "    #     print(f\"Size: {array.size}\")\n",
    "    #     print(f\"Data Type: {array.dtype}\")\n",
    "    #     print(f\"Sample Data (first 5 elements):\\n{array[:5] if array.ndim == 1 else array[:5, :5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 41519 but got size 45261 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m padded_trb \u001b[38;5;241m=\u001b[39m pad_embeddings(trb_embeddings, max_len)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Concatenate along sequence dimension\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m padded_combined \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([padded_tra, padded_trb, padded_epi], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Save padded embeddings\u001b[39;00m\n\u001b[1;32m     37\u001b[0m padd_paired_all_epi_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/embeddings/paired/allele/padded_Epitope_paired_embeddings.npz\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 41519 but got size 45261 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# raising error, because length tra != length trb.  To be solved.\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Paths to the embeddings files\n",
    "paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "\n",
    "# Load NPZ files\n",
    "epi_data = np.load(paired_all_epi_path, allow_pickle=True)\n",
    "tra_data = np.load(paired_all_tra_path, allow_pickle=True)\n",
    "trb_data = np.load(paired_all_trb_path, allow_pickle=True)\n",
    "\n",
    "# Extract embeddings\n",
    "epi_embeddings = [torch.tensor(epi_data[key]) for key in epi_data]\n",
    "tra_embeddings = [torch.tensor(tra_data[key]) for key in tra_data]\n",
    "trb_embeddings = [torch.tensor(trb_data[key]) for key in trb_data]\n",
    "\n",
    "# Find max sequence length\n",
    "max_len = max(max(e.shape[0] for e in epi_embeddings), \n",
    "              max(e.shape[0] for e in tra_embeddings), \n",
    "              max(e.shape[0] for e in trb_embeddings))\n",
    "\n",
    "# Pad sequences\n",
    "def pad_embeddings(embeddings, max_len):\n",
    "    return pad_sequence([torch.nn.functional.pad(e, (0, 0, 0, max_len - e.shape[0])) for e in embeddings], batch_first=True, padding_value=0.0)\n",
    "\n",
    "padded_epi = pad_embeddings(epi_embeddings, max_len)\n",
    "padded_tra = pad_embeddings(tra_embeddings, max_len)\n",
    "padded_trb = pad_embeddings(trb_embeddings, max_len)\n",
    "\n",
    "# Concatenate along sequence dimension\n",
    "padded_combined = torch.cat([padded_tra, padded_trb, padded_epi], dim=1)\n",
    "\n",
    "# Save padded embeddings\n",
    "padd_paired_all_epi_path = '../../data/embeddings/paired/allele/padded_Epitope_paired_embeddings.npz'\n",
    "padd_paired_all_tra_path = '../../data/embeddings/paired/allele/padded_TRA_paired_embeddings.npz'\n",
    "padd_paired_all_trb_path = '../../data/embeddings/paired/allele/padded_TRB_paired_embeddings.npz'\n",
    "padd_paired_combined_path = '../../data/embeddings/paired/allele/padded_Combined_paired_embeddings.npz'\n",
    "\n",
    "np.savez(padd_paired_all_epi_path, **{key: padded_epi[i].numpy() for i, key in enumerate(epi_data)})\n",
    "np.savez(padd_paired_all_tra_path, **{key: padded_tra[i].numpy() for i, key in enumerate(tra_data)})\n",
    "np.savez(padd_paired_all_trb_path, **{key: padded_trb[i].numpy() for i, key in enumerate(trb_data)})\n",
    "np.savez(padd_paired_combined_path, combined=padded_combined.numpy())\n",
    "\n",
    "print(\"Padded and concatenated embeddings saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beta and paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding embeddings using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.56 GiB of which 2.75 MiB is free. Including non-PyTorch memory, this process has 14.56 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 64.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# epi_embeddings = load_embeddings_to_gpu(paired_all_epi_path)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# tra_embeddings = load_embeddings_to_gpu(paired_all_tra_path)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# trb_embeddings = load_embeddings_to_gpu(paired_all_trb_path)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m beta_epi_embeddings \u001b[38;5;241m=\u001b[39m load_embeddings_to_gpu(beta_all_epi_path)\n\u001b[0;32m---> 27\u001b[0m beta_trb_embeddings \u001b[38;5;241m=\u001b[39m load_embeddings_to_gpu(beta_all_trb_path)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Find max sequence length\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# max_len = max(max(e.shape[0] for e in epi_embeddings.values()), \u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#               max(e.shape[0] for e in tra_embeddings.values()), \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#               max(e.shape[0] for e in trb_embeddings.values()))\u001b[39;00m\n\u001b[1;32m     34\u001b[0m beta_max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(e\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m beta_epi_embeddings\u001b[38;5;241m.\u001b[39mvalues()), \n\u001b[1;32m     35\u001b[0m                     \u001b[38;5;28mmax\u001b[39m(e\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m beta_trb_embeddings\u001b[38;5;241m.\u001b[39mvalues()))\n",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m, in \u001b[0;36mload_embeddings_to_gpu\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_embeddings_to_gpu\u001b[39m(path):\n\u001b[1;32m     19\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: torch\u001b[38;5;241m.\u001b[39mtensor(data[key], device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data}\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.56 GiB of which 2.75 MiB is free. Including non-PyTorch memory, this process has 14.56 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 64.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Paths to embeddings files\n",
    "# paired_all_epi_path = '../../data/embeddings/paired/allele/Epitope_paired_embeddings.npz'\n",
    "# paired_all_tra_path = '../../data/embeddings/paired/allele/TRA_paired_embeddings.npz'\n",
    "# paired_all_trb_path = '../../data/embeddings/paired/allele/TRB_paired_embeddings.npz'\n",
    "\n",
    "beta_all_epi_path = '../../data/embeddings/beta/allele/Epitope_beta_embeddings.npz'\n",
    "beta_all_trb_path = '../../data/embeddings/beta/allele/TRB_beta_embeddings.npz'\n",
    "\n",
    "# Load NPZ files into GPU\n",
    "def load_embeddings_to_gpu(path):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    return {key: torch.tensor(data[key], device=device) for key in data}\n",
    "\n",
    "# epi_embeddings = load_embeddings_to_gpu(paired_all_epi_path)\n",
    "# tra_embeddings = load_embeddings_to_gpu(paired_all_tra_path)\n",
    "# trb_embeddings = load_embeddings_to_gpu(paired_all_trb_path)\n",
    "\n",
    "beta_epi_embeddings = load_embeddings_to_gpu(beta_all_epi_path)\n",
    "beta_trb_embeddings = load_embeddings_to_gpu(beta_all_trb_path)\n",
    "\n",
    "# Find max sequence length\n",
    "# max_len = max(max(e.shape[0] for e in epi_embeddings.values()), \n",
    "#               max(e.shape[0] for e in tra_embeddings.values()), \n",
    "#               max(e.shape[0] for e in trb_embeddings.values()))\n",
    "\n",
    "beta_max_len = max(max(e.shape[0] for e in beta_epi_embeddings.values()), \n",
    "                    max(e.shape[0] for e in beta_trb_embeddings.values()))\n",
    "\n",
    "# Function to pad embeddings on GPU\n",
    "def pad_embeddings(embeddings, max_len):\n",
    "    return pad_sequence(\n",
    "        [torch.nn.functional.pad(e, (0, 0, 0, max_len - e.shape[0])) for e in embeddings.values()],\n",
    "        batch_first=True, padding_value=0.0\n",
    "    )\n",
    "\n",
    "# Pad embeddings (all computations on GPU)\n",
    "# padded_epi = pad_embeddings(epi_embeddings, max_len)\n",
    "# padded_tra = pad_embeddings(tra_embeddings, max_len)\n",
    "# padded_trb = pad_embeddings(trb_embeddings, max_len)\n",
    "\n",
    "padded_beta_epi = pad_embeddings(beta_epi_embeddings, beta_max_len)\n",
    "# padded_beta_trb = pad_embeddings(beta_trb_embeddings, beta_max_len)\n",
    "\n",
    "# Move back to CPU before saving\n",
    "# padded_epi = padded_epi.cpu().numpy()\n",
    "# padded_tra = padded_tra.cpu().numpy()\n",
    "# padded_trb = padded_trb.cpu().numpy()\n",
    "\n",
    "padded_beta_epi = padded_beta_epi.cpu().numpy()\n",
    "# padded_beta_trb = padded_beta_trb.cpu().numpy()\n",
    "\n",
    "# Save padded embeddings\n",
    "# padd_paired_all_epi_path = '../../data/embeddings/paired/allele/padded_Epitope_paired_embeddings.npz'\n",
    "# padd_paired_all_tra_path = '../../data/embeddings/paired/allele/padded_TRA_paired_embeddings.npz'\n",
    "# padd_paired_all_trb_path = '../../data/embeddings/paired/allele/padded_TRB_paired_embeddings.npz'\n",
    "\n",
    "padd_beta_all_epi_path = '../../data/embeddings/beta/allele/padded_Epitope_beta_embeddings.npz'\n",
    "# padd_beta_all_trb_path = '../../data/embeddings/beta/allele/padded_TRB_beta_embeddings.npz'\n",
    "\n",
    "# np.savez(padd_paired_all_epi_path, **{key: padded_epi[i] for i, key in enumerate(epi_embeddings)})\n",
    "# np.savez(padd_paired_all_tra_path, **{key: padded_tra[i] for i, key in enumerate(tra_embeddings)})\n",
    "# np.savez(padd_paired_all_trb_path, **{key: padded_trb[i] for i, key in enumerate(trb_embeddings)})\n",
    "\n",
    "np.savez(padd_beta_all_epi_path, **{key: padded_beta_epi[i] for i, key in enumerate(beta_epi_embeddings)})\n",
    "# np.savez(padd_beta_all_trb_path, **{key: padded_beta_trb[i] for i, key in enumerate(beta_trb_embeddings)})\n",
    "\n",
    "print(\"Padded embedding saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### short inspection into padded embeddings in directory prov.\n",
    "#### Just to check the Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the NPZ file: 1896\n",
      "\n",
      "Key: NLTTRTQL\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: FIYIFHTL\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: YMHHMELPT\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: ILLDWAANI\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: SMWALVISV\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: LYALVYFLQ\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: WLPTGTLLV\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: YVDDVVLGA\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: GTSGSPIVAR\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "\n",
      "Key: LTGHMLDMY\n",
      "Shape: (43, 1024)\n",
      "Size: 44032\n",
      "Data Type: float32\n",
      "Number of keys in the NPZ file: 10000\n",
      "\n",
      "Key: CASSSTASRNTGELFF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CASSLVTGEQYF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CASSAHRGGYGYTF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CASSLGRTGGNIQYF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CSARGQEGQYISYEQYF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CASSGKQGCDTEAFF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CASHQTGGRDTEAFF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CSASSPRLTSNQPQHF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CASSIIDGINLSYNEQFF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n",
      "\n",
      "Key: CASSLVGGELFF\n",
      "Shape: (38, 1024)\n",
      "Size: 38912\n",
      "Data Type: float32\n"
     ]
    }
   ],
   "source": [
    "paddedepiembpath = '../../data/embeddings/beta/gene/prov/padded_epitope_embeddings_batch_0.npz'\n",
    "paddedtcrembpath = '../../data/embeddings/beta/gene/prov/padded_tcr_embeddings_batch_0.npz'\n",
    "paths = [paddedepiembpath, paddedtcrembpath]\n",
    "for path in paths:\n",
    "    # Load the NPZ file\n",
    "    data = np.load(path)\n",
    "\n",
    "    # Print available keys in the file\n",
    "    print(\"Number of keys in the NPZ file:\", len(data.files))\n",
    "\n",
    "    # Inspect the shape and size of each stored array\n",
    "    for key in data.files[:10]:\n",
    "        array = data[key]\n",
    "        print(f\"\\nKey: {key}\")\n",
    "        print(f\"Shape: {array.shape}\")\n",
    "        print(f\"Size: {array.size}\")\n",
    "        print(f\"Data Type: {array.dtype}\")\n",
    "        # print(f\"Sample Data (first 5 elements):\\n{array[:5] if array.ndim == 1 else array[:5, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "## Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Baseline Transformer Block \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)  # Normalization for stability\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout to prevent overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multihead Attention with Residual Connection\n",
    "        attn_output, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))  # Add & Norm\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65930/2300908741.py:8: DtypeWarning: Columns (1,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv(train_path, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the training and validation data\n",
    "train_path = '../../data/splitted_datasets/allele/beta/train.tsv'\n",
    "validation_path = '../../data/splitted_datasets/allele/beta/validation.tsv'\n",
    "\n",
    "train_data = pd.read_csv(train_path, sep='\\t')\n",
    "validation_data = pd.read_csv(validation_path, sep='\\t')\n",
    "\n",
    "# Load the embeddings\n",
    "tcr_embeddings_path = '../../data/embeddings/beta/allele/TRB_beta_embeddings.npz'\n",
    "epitope_embeddings_path = '../../data/embeddings/beta/allele/Epitope_beta_embeddings.npz'\n",
    "\n",
    "tcr_embeddings = np.load(tcr_embeddings_path, allow_pickle=True)\n",
    "epitope_embeddings = np.load(epitope_embeddings_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Padding the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_embeddings(embeddings_dict, max_length):\n",
    "#     padded_embeddings = {}\n",
    "#     for key, embedding in embeddings_dict.items():\n",
    "#         padded_embedding = np.zeros((max_length, embedding.shape[1]))\n",
    "#         padded_embedding[:embedding.shape[0], :] = embedding\n",
    "#         padded_embeddings[key] = padded_embedding\n",
    "#     return padded_embeddings\n",
    "\n",
    "# # Determine the maximum length for TCR and Epitope embeddings\n",
    "# max_tcr_length = max([embedding.shape[0] for embedding in tcr_embeddings.values()])\n",
    "# max_epitope_length = max([embedding.shape[0] for embedding in epitope_embeddings.values()])\n",
    "\n",
    "# # Pad the embeddings\n",
    "# padded_tcr_embeddings = pad_embeddings(tcr_embeddings, max_tcr_length)\n",
    "# padded_epitope_embeddings = pad_embeddings(epitope_embeddings, max_epitope_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def pad_embeddings_in_batches(embeddings_dict, max_length, batch_size, save_path):\n",
    "    \"\"\"\n",
    "    Pad embeddings in batches and save them incrementally to disk.\n",
    "    \"\"\"\n",
    "    keys = list(embeddings_dict.keys())\n",
    "    num_batches = (len(keys) + batch_size - 1) // batch_size  # Calculate number of batches\n",
    "\n",
    "    # Create a directory to save the batches\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch_keys = keys[i * batch_size : (i + 1) * batch_size]\n",
    "        padded_batch = {}\n",
    "\n",
    "        for key in batch_keys:\n",
    "            embedding = embeddings_dict[key]\n",
    "            padded_embedding = np.zeros((max_length, embedding.shape[1]), dtype=embedding.dtype)\n",
    "            padded_embedding[:embedding.shape[0], :] = embedding\n",
    "            padded_batch[key] = padded_embedding\n",
    "\n",
    "        # Save the batch to disk\n",
    "        batch_save_path = f\"{save_path}_batch_{i}.npz\"\n",
    "        np.savez_compressed(batch_save_path, **padded_batch)\n",
    "        print(f\"Saved batch {i + 1}/{num_batches} to {batch_save_path}\")\n",
    "\n",
    "    print(\"All batches saved successfully!\")\n",
    "\n",
    "# Define batch size (adjust based on memory availability)\n",
    "batch_size = 10000  # Process 10000 embeddings at a time\n",
    "\n",
    "# Determine the maximum length for TCR and Epitope embeddings\n",
    "max_tcr_length = max([embedding.shape[0] for embedding in tcr_embeddings.values()])\n",
    "max_epitope_length = max([embedding.shape[0] for embedding in epitope_embeddings.values()])\n",
    "\n",
    "# # Pad and save TCR embeddings in batches\n",
    "# pad_embeddings_in_batches(tcr_embeddings, max_tcr_length, batch_size, '../../data/embeddings/beta/gene/prov/padded_tcr_embeddings')\n",
    "\n",
    "# # Pad and save Epitope embeddings in batches\n",
    "# pad_embeddings_in_batches(epitope_embeddings, max_epitope_length, batch_size, '../../data/embeddings/beta/gene/prov/padded_epitope_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 43\n"
     ]
    }
   ],
   "source": [
    "print(max_tcr_length, max_epitope_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40000 embeddings from 3 batches.\n",
      "Loaded 1896 embeddings from 1 batches.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_padded_embeddings(save_path_pattern):\n",
    "    \"\"\"\n",
    "    Load padded embeddings saved in batches.\n",
    "    \"\"\"\n",
    "    padded_embeddings = {}\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        batch_path = f\"{save_path_pattern}_batch_{i}.npz\"\n",
    "        if not os.path.exists(batch_path):\n",
    "            break  # Stop if no more batches exist\n",
    "\n",
    "        batch = np.load(batch_path, allow_pickle=True)\n",
    "        for key in batch.files:\n",
    "            padded_embeddings[key] = batch[key]\n",
    "        \n",
    "        # if i == 3: # prov\n",
    "        #     break\n",
    "        i += 1\n",
    "\n",
    "    print(f\"Loaded {len(padded_embeddings)} embeddings from {i} batches.\")\n",
    "    return padded_embeddings\n",
    "\n",
    "# Load TCR embeddings\n",
    "padded_tcr_embeddings = load_padded_embeddings('../../data/embeddings/beta/gene/prov/padded_tcr_embeddings')\n",
    "\n",
    "# Load Epitope embeddings\n",
    "padded_epitope_embeddings = load_padded_embeddings('../../data/embeddings/beta/gene/prov/padded_epitope_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the padded embeddings\n",
    "# padded_tcr_embeddings = np.load(save_dir + 'padded_tcr_embeddings.npz', allow_pickle=True)\n",
    "# padded_epitope_embeddings = np.load(save_dir + 'padded_epitope_embeddings.npz', allow_pickle=True)\n",
    "\n",
    "# Convert the loaded data back into dictionaries\n",
    "padded_tcr_embeddings = {key: padded_tcr_embeddings[key] for key in padded_tcr_embeddings.files}\n",
    "padded_epitope_embeddings = {key: padded_epitope_embeddings[key] for key in padded_epitope_embeddings.files}\n",
    "\n",
    "print(\"Padded embeddings loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tcr_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Verify TCR embeddings\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m tcr_embeddings:\n\u001b[1;32m      3\u001b[0m     original \u001b[38;5;241m=\u001b[39m tcr_embeddings[key]\n\u001b[1;32m      4\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m padded_tcr_embeddings[key]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tcr_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "# Verify TCR embeddings\n",
    "for key in tcr_embeddings:\n",
    "    original = tcr_embeddings[key]\n",
    "    loaded = padded_tcr_embeddings[key]\n",
    "    assert np.array_equal(original, loaded[:original.shape[0], :]), f\"Mismatch in TCR embedding for key: {key}\"\n",
    "\n",
    "# Verify epitope embeddings\n",
    "for key in epitope_embeddings:\n",
    "    original = epitope_embeddings[key]\n",
    "    loaded = padded_epitope_embeddings[key]\n",
    "    assert np.array_equal(original, loaded[:original.shape[0], :]), f\"Mismatch in epitope embedding for key: {key}\"\n",
    "\n",
    "print(\"Embeddings verified successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TCR_name         TRBV        TRBJ            TRB_CDR3 TRBC    Epitope  \\\n",
    "# 0      257  TRBV20-1*01  TRBJ2-5*01  CSARIWPYPAGGEETQYF  NaN  KLGGALQAK   \n",
    "# 1      358    TRBV28*01  TRBJ2-1*01     CASSKGLAGLDEQFF  NaN   RAKFKQLL   \n",
    "# 2      382   TRBV6-6*01  TRBJ2-5*01     CATQTPDSRRETQYF  NaN  KLGGALQAK   \n",
    "# 3      393  TRBV20-1*01  TRBJ1-2*01     CSARDLDSLTNGYTF  NaN  KLGGALQAK   \n",
    "# 4      396  TRBV10-2*01  TRBJ2-7*01       CASSEDREDEQYF  NaN  KLGGALQAK   \n",
    "\n",
    "#            MHC  Binding  task  \n",
    "# 0  HLA-A*03:01        1   NaN  \n",
    "# 1  HLA-B*08:01        1   NaN  \n",
    "# 2  HLA-A*03:01        1   NaN  \n",
    "# 3  HLA-A*03:01        1   NaN  \n",
    "# 4  HLA-A*03:01        1   NaN  \n",
    "# Train dataset length: 319226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Creating the Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TCR_Epitope_Dataset(Dataset):\n",
    "    def __init__(self, data, tcr_embeddings, epitope_embeddings):\n",
    "        self.data = data\n",
    "        self.tcr_embeddings = tcr_embeddings\n",
    "        self.epitope_embeddings = epitope_embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        tcr_key = row['TRB_CDR3']\n",
    "        epitope_key = row['Epitope']\n",
    "        label = row['Binding']\n",
    "        \n",
    "        tcr_embedding = self.tcr_embeddings[tcr_key]\n",
    "        epitope_embedding = self.epitope_embeddings[epitope_key]\n",
    "        \n",
    "        # Convert embeddings to torch.float32\n",
    "        tcr_embedding = torch.tensor(tcr_embedding, dtype=torch.float32)\n",
    "        epitope_embedding = torch.tensor(epitope_embedding, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return tcr_embedding, epitope_embedding, label\n",
    "\n",
    "        # Create the datasets\n",
    "train_dataset = TCR_Epitope_Dataset(train_data, padded_tcr_embeddings, padded_epitope_embeddings)\n",
    "validation_dataset = TCR_Epitope_Dataset(validation_data, padded_tcr_embeddings, padded_epitope_embeddings)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCR_Epitope_Transformer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, num_layers, max_tcr_length, max_epitope_length, dropout=0.1):\n",
    "        super(TCR_Epitope_Transformer, self).__init__()\n",
    "        \n",
    "        # TCR and Epitope embedding layers\n",
    "        self.tcr_embedding = nn.Linear(1024, embed_dim)\n",
    "        self.epitope_embedding = nn.Linear(1024, embed_dim)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        self.tcr_positional_encoding = nn.Parameter(torch.zeros(1, max_tcr_length, embed_dim))\n",
    "        self.epitope_positional_encoding = nn.Parameter(torch.zeros(1, max_epitope_length, embed_dim))\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            AttentionBlock(embed_dim, num_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(embed_dim, 1)\n",
    "        \n",
    "    def forward(self, tcr, epitope):\n",
    "        # Embed TCR and Epitope\n",
    "        tcr = self.tcr_embedding(tcr) + self.tcr_positional_encoding\n",
    "        epitope = self.epitope_embedding(epitope) + self.epitope_positional_encoding\n",
    "        \n",
    "        # Concatenate TCR and Epitope embeddings\n",
    "        combined = torch.cat((tcr, epitope), dim=1)\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            combined = layer(combined)\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        pooled = combined.mean(dim=1)\n",
    "        \n",
    "        # Output layer\n",
    "        output = self.output_layer(pooled)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize the model\n",
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "num_layers = 4\n",
    "model = TCR_Epitope_Transformer(embed_dim, num_heads, num_layers, max_tcr_length, max_epitope_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CASSPPAGGQGAYEQYF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tcr, epitope, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     12\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mTCR_Epitope_Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m epitope_key \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpitope\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m label \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBinding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m tcr_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtcr_embeddings[tcr_key]\n\u001b[1;32m     18\u001b[0m epitope_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepitope_embeddings[epitope_key]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Convert embeddings to torch.float32\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CASSPPAGGQGAYEQYF'"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2 # 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for tcr, epitope, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(tcr, epitope)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for tcr, epitope, labels in validation_loader:\n",
    "        outputs = model(tcr, epitope)\n",
    "        predicted = torch.sigmoid(outputs) > 0.5\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze() == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Checking if Things are Working Properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example check for shapes\n",
    "for tcr, epitope, labels in train_loader:\n",
    "    print(f'TCR shape: {tcr.shape}')\n",
    "    print(f'Epitope shape: {epitope.shape}')\n",
    "    print(f'Labels shape: {labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the future pipeline v1 could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### old attempts to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, n_heads, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: Dimensionality of the input embeddings.\n",
    "            n_heads: Number of attention heads.\n",
    "            dropout: Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        # Multihead Attention\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, n_heads, dropout=dropout)\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Feedforward Network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 * embed_dim),  # Expand dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim)   # Compress back to original dimension\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (seq_len, batch_size, embed_dim).\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor of shape (seq_len, batch_size, embed_dim).\n",
    "        \"\"\"\n",
    "        # Multihead Attention\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)  # Self-attention\n",
    "        x = x + self.dropout(attn_output)              # Residual connection\n",
    "        x = self.norm1(x)                              # Layer normalization\n",
    "        \n",
    "        # Feedforward Network\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = x + self.dropout(ffn_output)               # Residual connection\n",
    "        x = self.norm2(x)                              # Layer normalization\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Testing the Updated Dataset\\\n",
    "Let's test the updated dataset to ensure the combined embeddings are in the correct shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in TCR embeddings file: ['embeddings', 'labels']\n",
      "Keys in Epitope embeddings file: ['embeddings']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the .npz files\n",
    "tcr_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz')\n",
    "epitope_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_Epitope_embeddings.npz')\n",
    "\n",
    "# Print the keys in each file\n",
    "print(\"Keys in TCR embeddings file:\", list(tcr_data.keys()))\n",
    "print(\"Keys in Epitope embeddings file:\", list(epitope_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK!!  \n",
    "\\\n",
    "Step 1: Verify the Size of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TCR embeddings: 570500\n",
      "Number of epitope embeddings: 570500\n"
     ]
    }
   ],
   "source": [
    "# Load the TCR and epitope embeddings\n",
    "tcr_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz')\n",
    "epitope_data = np.load('/home/ubuntu/data/embeddings/beta/gene/TCRPeg_Epitope_embeddings.npz')\n",
    "\n",
    "tcr_embeddings = tcr_data['embeddings']  # Use the correct key\n",
    "epitope_embeddings = epitope_data['embeddings']  # Use the correct key\n",
    "\n",
    "print(f\"Number of TCR embeddings: {len(tcr_embeddings)}\")\n",
    "print(f\"Number of epitope embeddings: {len(epitope_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Ensure Labels Match the Dataset Size\\\n",
    "If you have labels, ensure the labels array has the same length as the number of TCR/epitope embeddings. If you don't have labels, we can create dummy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 570500\n"
     ]
    }
   ],
   "source": [
    "# If you have labels, load them here\n",
    "path_to_labels = '/home/ubuntu/data/embeddings/beta/gene/TCRPeg_tcr_embeddings.npz'\n",
    "labels_data = np.load(path_to_labels)  # Example: Load labels from a file\n",
    "labels = labels_data['labels']\n",
    "\n",
    "# If you don't have labels, create dummy labels\n",
    "# labels = np.zeros(len(tcr_embeddings))  # Dummy labels (all zeros)\n",
    "\n",
    "print(f\"Number of labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation and test\\\n",
    "This is only a dummy splitting, since for real testing we'll use \n",
    "a separate test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% training\n",
    "val_size = len(dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Update the Dataset Class \\\n",
    "Update the TCR_Epitope_Dataset class to ensure it uses the correct indices and handles the dataset size properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCR_Epitope_Dataset(Dataset):\n",
    "    def __init__(self, tcr_embeddings, epitope_embeddings, labels=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tcr_embeddings: Array of TCR embeddings.\n",
    "            epitope_embeddings: Array of epitope embeddings.\n",
    "            labels: Optional array of labels (1 for binding, 0 for non-binding).\n",
    "        \"\"\"\n",
    "        self.tcr_embeddings = tcr_embeddings\n",
    "        self.epitope_embeddings = epitope_embeddings\n",
    "        \n",
    "        # Ensure the number of TCR and epitope embeddings match\n",
    "        assert len(self.tcr_embeddings) == len(self.epitope_embeddings), \\\n",
    "            \"Number of TCR and epitope embeddings must match!\"\n",
    "        \n",
    "        # If labels are provided, use them; otherwise, create dummy labels\n",
    "        self.labels = labels if labels is not None else np.zeros(len(self.tcr_embeddings))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tcr_embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            combined_embedding: Combined TCR and epitope embeddings of shape (2, 1024).\n",
    "            label: Binding label (1 or 0).\n",
    "        \"\"\"\n",
    "        tcr_embedding = self.tcr_embeddings[idx]\n",
    "        epitope_embedding = self.epitope_embeddings[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        tcr_embedding = torch.tensor(tcr_embedding, dtype=torch.float32)\n",
    "        epitope_embedding = torch.tensor(epitope_embedding, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        # Combine TCR and epitope embeddings along the sequence dimension\n",
    "        combined_embedding = torch.stack([tcr_embedding, epitope_embedding], dim=0)  # Shape: (2, 1024)\n",
    "        \n",
    "        return combined_embedding, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Create the Dataset and DataLoader \\\n",
    "Now, create the dataset and DataLoader with the correct data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 570500\n",
      "Combined embedding shape: torch.Size([2, 1024])\n",
      "Label: 1.0\n",
      "Combined embeddings batch shape: torch.Size([32, 2, 1024])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = TCR_Epitope_Dataset(tcr_embeddings, epitope_embeddings, labels)\n",
    "\n",
    "# Inspect the dataset\n",
    "print(f\"Number of samples: {len(dataset)}\")\n",
    "combined_embedding, label = dataset[0]  # Get the first sample\n",
    "print(f\"Combined embedding shape: {combined_embedding.shape}\")  # Should be (2, 1024)\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    combined_embeddings, labels = batch\n",
    "    print(f\"Combined embeddings batch shape: {combined_embeddings.shape}\")  # Should be (batch_size, 2, 1024)\n",
    "    print(f\"Labels batch shape: {labels.shape}\")  # Should be (batch_size,)\n",
    "    break  # Stop after the first batch for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Integrate the Transformer Block\\\n",
    "We'll create a model class that:\n",
    "\n",
    "Takes the combined TCR and epitope embeddings as input.\n",
    "\n",
    "Passes them through the TransformerBlock.\n",
    "\n",
    "Flattens the output and passes it through a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TCR_Epitope_Model(nn.Module):\n",
    "    def __init__(self, embed_dim, n_heads, dropout=0.1, classifier_hidden_dim=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim: Dimensionality of the input embeddings (1024 in your case).\n",
    "            n_heads: Number of attention heads in the transformer.\n",
    "            dropout: Dropout rate for regularization.\n",
    "            classifier_hidden_dim: Hidden dimension of the classifier.\n",
    "        \"\"\"\n",
    "        super(TCR_Epitope_Model, self).__init__()\n",
    "        \n",
    "        # Transformer Block\n",
    "        self.transformer_block = TransformerBlock(embed_dim, n_heads, dropout)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * embed_dim, classifier_hidden_dim),  # Input: flattened transformer output\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(classifier_hidden_dim, 1)  # Output: binary prediction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 2, embed_dim).\n",
    "        \n",
    "        Returns:\n",
    "            logits: Output tensor of shape (batch_size, 1).\n",
    "        \"\"\"\n",
    "        # Permute input to (seq_len, batch_size, embed_dim) for the transformer\n",
    "        x = x.permute(1, 0, 2)  # Shape: (2, batch_size, embed_dim)\n",
    "        \n",
    "        # Pass through the transformer block\n",
    "        x = self.transformer_block(x)  # Shape: (2, batch_size, embed_dim)\n",
    "        \n",
    "        # Permute back to (batch_size, seq_len, embed_dim)\n",
    "        x = x.permute(1, 0, 2)  # Shape: (batch_size, 2, embed_dim)\n",
    "        \n",
    "        # Flatten the output\n",
    "        x = x.reshape(x.size(0), -1)  # Shape: (batch_size, 2 * embed_dim)\n",
    "        \n",
    "        # Pass through the classifier\n",
    "        logits = self.classifier(x)  # Shape: (batch_size, 1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Test the Model \\\n",
    "Let's test the model with a batch of data to ensure everything works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# # Initialize the model\n",
    "# embed_dim = 1024  # Dimensionality of TCR and epitope embeddings\n",
    "# n_heads = 4       # Number of attention heads\n",
    "# model = TCR_Epitope_Model(embed_dim, n_heads)\n",
    "\n",
    "# # Get a batch of data from the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     combined_embeddings, labels = batch\n",
    "#     break  # Stop after the first batch\n",
    "\n",
    "# # Pass the batch through the model\n",
    "# logits = model(combined_embeddings)\n",
    "# print(f\"Logits shape: {logits.shape}\")  # Should be (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we forgot to use GPU. Then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: Tesla T4\n",
      "Model is on: cuda:0\n",
      "Data is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Using CPU.\")\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "model = model.to(device)\n",
    "\n",
    "# Move Data to GPU\n",
    "\n",
    "for batch in dataloader:\n",
    "    combined_embeddings, labels = batch\n",
    "    \n",
    "    # Move data to the GPU (if available)\n",
    "    combined_embeddings = combined_embeddings.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Rest of the training loop...\n",
    "\n",
    "# Verify GPU Usage\n",
    "\n",
    "# Check model device\n",
    "print(f\"Model is on: {next(model.parameters()).device}\")\n",
    "\n",
    "# Check data device\n",
    "print(f\"Data is on: {combined_embeddings.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Add a Training Loop\\\n",
    "Now, let's add a simple training loop to train the model. We'll use binary cross-entropy loss and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.30530472857386276\n",
      "Epoch 2/5, Loss: 0.1719683983865046\n",
      "Epoch 3/5, Loss: 0.157329112976129\n",
      "Epoch 4/5, Loss: 0.14955465956043631\n",
      "Epoch 5/5, Loss: 0.14537664496026595\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = TCR_Epitope_Model(embed_dim, n_heads).to(device)  # Move model to GPU\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        \n",
    "        # Move data to the GPU (if available)\n",
    "        combined_embeddings = combined_embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(combined_embeddings).squeeze()  # Shape: (batch_size,)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Prepare a Validation Set\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% training\n",
    "val_size = len(dataset) - train_size   # 20% validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 2: Evaluation Function\\\n",
    "We'll write a function to evaluate the model on the validation set. This function will:\n",
    "\n",
    "Switch the model to evaluation mode.\n",
    "\n",
    "Disable gradient computation.\n",
    "\n",
    "Compute predictions and metrics like accuracy, ROC-AUC, and precision-recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in dataloader:\n",
    "            combined_embeddings, labels = batch\n",
    "            \n",
    "            # Move data to the GPU (if available)\n",
    "            combined_embeddings = combined_embeddings.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(combined_embeddings).squeeze()\n",
    "            predictions = torch.sigmoid(logits)  # Convert logits to probabilities\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions > 0.5)  # Threshold at 0.5\n",
    "    roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions > 0.5, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions > 0.5, zero_division=0)\n",
    "    \n",
    "    return accuracy, roc_auc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for batch in train_dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        \n",
    "        # Move data to the GPU (if available)\n",
    "        combined_embeddings = combined_embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(combined_embeddings).squeeze()\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print training loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_dataloader)}\")\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    accuracy, roc_auc, precision, recall = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Metrics - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"tcr_epitope_model.pth\")\n",
    "\n",
    "# To load the model later:\n",
    "\n",
    "# Load the model\n",
    "model = TCR_Epitope_Model(embed_dim, n_heads).to(device)\n",
    "model.load_state_dict(torch.load(\"tcr_epitope_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with hyperparameter tuning, test set evaluation, and visualizations for your Multihead Attention Model. We'll break this down into clear steps. \n",
    "\n",
    "Step 1: Hyperparameter Tuning \\\n",
    "Hyperparameter tuning involves finding the best set of hyperparameters (e.g., learning rate, number of attention heads, dropout rate) for your model. We'll use a simple grid search approach.\n",
    "\n",
    "Key Hyperparameters to Tune:\n",
    "\n",
    "Learning Rate: Controls the step size during optimization.\n",
    "\n",
    "Number of Attention Heads: Determines how many parallel attention mechanisms to use.\n",
    "\n",
    "Dropout Rate: Regularization to prevent overfitting.\n",
    "\n",
    "Hidden Dimension of the Classifier: Size of the hidden layer in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define hyperparameter grid\n",
    "learning_rates = [1e-3, 1e-4]\n",
    "n_heads_list = [2, 4, 8]\n",
    "dropout_rates = [0.1, 0.2]\n",
    "classifier_hidden_dims = [64, 128]\n",
    "\n",
    "# Iterate over all combinations\n",
    "best_roc_auc = 0\n",
    "best_hyperparams = {}\n",
    "\n",
    "for lr, n_heads, dropout, hidden_dim in product(learning_rates, n_heads_list, dropout_rates, classifier_hidden_dims):\n",
    "    print(f\"Testing: lr={lr}, n_heads={n_heads}, dropout={dropout}, hidden_dim={hidden_dim}\")\n",
    "    \n",
    "    # Initialize model with current hyperparameters\n",
    "    model = TCR_Epitope_Model(embed_dim=1024, n_heads=n_heads, dropout=dropout, classifier_hidden_dim=hidden_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(5):  # Short training for hyperparameter tuning\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            combined_embeddings, labels = batch\n",
    "            combined_embeddings, labels = combined_embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(combined_embeddings).squeeze()\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    accuracy, roc_auc, precision, recall = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Metrics - Accuracy: {accuracy:.4f}, ROC-AUC: {roc_auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Track the best hyperparameters\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_roc_auc = roc_auc\n",
    "        best_hyperparams = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"n_heads\": n_heads,\n",
    "            \"dropout\": dropout,\n",
    "            \"classifier_hidden_dim\": hidden_dim\n",
    "        }\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}, Best ROC-AUC: {best_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Test Set Evaluation \\\n",
    "Once you've identified the best hyperparameters, evaluate the model on the test set.\n",
    "\n",
    "Load the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test embeddings (assuming Scenario B: shared embeddings)\n",
    "test_tcr_embeddings = all_tcr_embeddings[test_tcr_indices]\n",
    "test_epitope_embeddings = all_epitope_embeddings[test_epitope_indices]\n",
    "\n",
    "# Create test dataset and DataLoader\n",
    "test_dataset = TCR_Epitope_Dataset(test_tcr_embeddings, test_epitope_embeddings, test_labels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the best hyperparameters\n",
    "best_model = TCR_Epitope_Model(\n",
    "    embed_dim=1024,\n",
    "    n_heads=best_hyperparams[\"n_heads\"],\n",
    "    dropout=best_hyperparams[\"dropout\"],\n",
    "    classifier_hidden_dim=best_hyperparams[\"classifier_hidden_dim\"]\n",
    ").to(device)\n",
    "\n",
    "# Load the trained weights (if you saved the model)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy, test_roc_auc, test_precision, test_recall = evaluate(best_model, test_dataloader, device)\n",
    "print(f\"Test Metrics - Accuracy: {test_accuracy:.4f}, ROC-AUC: {test_roc_auc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Visualizations \\\n",
    "Visualizations help you understand the model's performance. We'll create:\n",
    "\n",
    "ROC Curve: To visualize the trade-off between true positive rate (TPR) and false positive rate (FPR).\n",
    "\n",
    "Precision-Recall Curve: To visualize the trade-off between precision and recall.\n",
    "\n",
    "Confusion Matrix: To show the distribution of predictions.\n",
    "\n",
    "ROC Curve:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions and labels\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        combined_embeddings, labels = batch\n",
    "        combined_embeddings, labels = combined_embeddings.to(device), labels.to(device)\n",
    "        \n",
    "        logits = best_model(combined_embeddings).squeeze()\n",
    "        predictions = torch.sigmoid(logits)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(all_labels, all_predictions)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "binary_predictions = (np.array(all_predictions) > 0.5).astype(int)\n",
    "cm = confusion_matrix(all_labels, binary_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Binding', 'Binding'], yticklabels=['Not Binding', 'Binding'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

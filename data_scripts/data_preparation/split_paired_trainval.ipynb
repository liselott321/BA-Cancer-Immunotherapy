{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if not 'precision' in locals():\n",
    "  precision = \"gene\" # allele or gene\n",
    "\n",
    "if not 'input_file' in locals():\n",
    "  input_file = f\"../../data_10x/customDatasets/{precision}/paired_concatenated.tsv\"\n",
    "df = pd.read_csv(input_file, sep='\\t', low_memory=False)\n",
    "\n",
    "if not 'paired_output_folder' in locals():\n",
    "  paired_output_folder = f\"../../data_10x/splitted_data/{precision}/paired\"\n",
    "\n",
    "if not 'validation_file_name' in locals():\n",
    "  validation_file_name = \"validation.tsv\"\n",
    "\n",
    "if not 'train_file_name' in locals():\n",
    "  train_file_name = \"train.tsv\"\n",
    "\n",
    "if not 'aimed_validation_ratio' in locals():\n",
    "  aimed_validation_ratio = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data entries (without negative data) is analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcr_key = \"tcr_key\"\n",
    "\n",
    "df[tcr_key] = df['TRA_CDR3'].astype(str) + '_' + df['TRB_CDR3'].astype(str)\n",
    "\n",
    "\n",
    "distinct_tcrs = df.drop_duplicates(subset=[tcr_key], keep=\"first\", inplace=False)\n",
    "unique_epitopes = df.drop_duplicates(subset=[\"Epitope\"], keep=False, inplace=False)\n",
    "unique_tcrs = df.drop_duplicates(subset=[tcr_key], keep=False, inplace=False)\n",
    "\n",
    "\n",
    "print(f\"distinct tcr's: {len(distinct_tcrs)} from {len(df)}\")\n",
    "print(f\"unique tcr's: {len(unique_tcrs)} from {len(df)}\")\n",
    "print(f\"unique epitopes: {len(unique_epitopes['Epitope'])} from {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a train and validation set is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df, unique_tcrs, how='left', indicator=True)\n",
    "df_train = df_train[df_train['_merge'] == 'left_only']\n",
    "\n",
    "seen_epitopes = set(df_train[\"Epitope\"])\n",
    "seen_tcrs = set(df_train[\"tcr_key\"])\n",
    "\n",
    "def assign_tpp(row):\n",
    "    \"\"\"Weist eine TPP-Kategorie gemäß der Definition zu.\"\"\"\n",
    "    epitope_seen = row[\"Epitope\"] in seen_epitopes\n",
    "    tcr_seen = row[\"tcr_key\"] in seen_tcrs\n",
    "\n",
    "    if epitope_seen and tcr_seen:\n",
    "        return \"TPP1\"  # Both TCR & Epitope seen\n",
    "    elif epitope_seen and not tcr_seen:\n",
    "        return \"TPP2\"  # Epitope seen, but TCR unknown\n",
    "    elif not epitope_seen and not tcr_seen:\n",
    "        return \"TPP3\"  # Neither TCR nor Epitope seen\n",
    "    elif not epitope_seen and tcr_seen:\n",
    "        return \"TPP4\"  # TCR seen, but Epitope unknown\n",
    "    return \"Unknown\"  # Falls etwas schiefgeht\n",
    "\n",
    "df_train[\"task\"] = df_train.apply(assign_tpp, axis=1)\n",
    "\n",
    "df_validation = df.sample(frac=0.2, random_state=42)\n",
    "df_validation[\"task\"] = df_validation.apply(assign_tpp, axis=1)\n",
    "\n",
    "number_of_TPP4 = (df_validation['task'] == 'TPP4').sum()\n",
    "number_of_TPP3 = (df_validation['task'] == 'TPP3').sum()\n",
    "number_of_TPP2 = (df_validation['task'] == 'TPP2').sum()\n",
    "number_of_TPP1 = (df_validation['task'] == 'TPP1').sum()\n",
    "validation_ratio = len(df_validation) / (len(df_train) + len(df_validation))\n",
    "\n",
    "print(f\"train data has {len(df_train)} entries\")\n",
    "print(f\"validation data has {len(df_validation)} entries\")\n",
    "print(f\"validation data has {number_of_TPP1} TPP1 tasks (unseen tcr & seen epitopes).\")\n",
    "print(f\"validation data has {number_of_TPP2} TPP2 tasks (unseen tcr & seen epitopes).\")\n",
    "print(f\"validation data has {number_of_TPP3} TPP3 tasks (unseen tcr & unseen epitope).\")\n",
    "print(f\"validation data has {number_of_TPP4} TPP4 tasks (unseen tcr & unseen epitope).\")\n",
    "print(f\"the train/validation ratio is {(1-validation_ratio)}/{validation_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validation_ratio < aimed_validation_ratio:\n",
    "    missing_validation_count = math.ceil((aimed_validation_ratio - validation_ratio) * (len(df_validation) + len(df_train)))\n",
    "    print(f\"{missing_validation_count} Entries need to be shifted from Train to Validation\")\n",
    "\n",
    "    # Bevorzuge `TPP1`-Einträge für den Shift\n",
    "    filtered_rows = df_train[df_train[\"task\"] == \"TPP1\"].head(missing_validation_count)\n",
    "\n",
    "    # Falls nicht genug `TPP1` vorhanden sind, nutze `TPP2` als Fallback\n",
    "    if len(filtered_rows) < missing_validation_count:\n",
    "        print(f\"Not enough TPP1 entries available ({len(filtered_rows)} found), using TPP2 as fallback!\")\n",
    "        additional_needed = missing_validation_count - len(filtered_rows)\n",
    "        fallback_rows = df_train[df_train[\"task\"] == \"TPP2\"].head(additional_needed)\n",
    "        filtered_rows = pd.concat([filtered_rows, fallback_rows], ignore_index=True)\n",
    "\n",
    "    # Verschiebe `TPP1` (und ggf. `TPP2`) von Train → Validation\n",
    "    print(\"**Verschiebe von Train → Validation:**\")\n",
    "    print(f\"Train (vorher): {len(df_train)} entries\")\n",
    "    print(f\"Validation (vorher): {len(df_validation)} entries\")\n",
    "\n",
    "    df_validation = pd.concat([df_validation, filtered_rows], ignore_index=True)\n",
    "    df_train = df_train.drop(filtered_rows.index)\n",
    "\n",
    "    print(f\"Moved {len(filtered_rows)} entries from Train to Validation\")\n",
    "    print(f\"Train (nachher): {len(df_train)} entries\")\n",
    "    print(f\"Validation (nachher): {len(df_validation)} entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speicherung der gesplitteten Daten\n",
    "df_train.drop(columns=[\"_merge\", \"tcr_key\"], inplace=True, errors='ignore')\n",
    "df_validation.drop(columns=[\"_merge\", \"tcr_key\"], inplace=True, errors='ignore')\n",
    "\n",
    "df_train.to_csv(f\"{paired_output_folder}/{train_file_name}\", sep=\"\\t\", index=False)\n",
    "df_validation.to_csv(f\"{paired_output_folder}/{validation_file_name}\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train data has {len(df_train)} entries\")\n",
    "print(f\"validation data has {len(df_validation)} entries\")\n",
    "print(f\"validation data has {number_of_TPP1} TPP1 tasks (unseen tcr & seen epitopes).\")\n",
    "print(f\"validation data has {number_of_TPP2} TPP2 tasks (unseen tcr & seen epitopes).\")\n",
    "print(f\"validation data has {number_of_TPP3} TPP3 tasks (unseen tcr & unseen epitope).\")\n",
    "print(f\"validation data has {number_of_TPP4} TPP4 tasks (unseen tcr & unseen epitope).\")\n",
    "print(f\"the train/validation ratio is {(1-validation_ratio)}/{validation_ratio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

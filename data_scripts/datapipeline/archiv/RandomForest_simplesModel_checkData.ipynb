{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe4a6b9-e4f6-432f-8c21-9d2a816fdb84",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675662c-4fb1-43dd-9032-814120bc7ce3",
   "metadata": {},
   "source": [
    "1) Laden der Split-DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d29d51e2-8f87-470c-ae2a-aed8f44bb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "BASE = \"../../../../data/splitted_datasets/allele/beta/new\"\n",
    "train_df = pd.read_csv(os.path.join(BASE, \"train.tsv\"),      sep=\"\\t\", dtype=str)\n",
    "val_df   = pd.read_csv(os.path.join(BASE, \"validation.tsv\"), sep=\"\\t\", dtype=str)\n",
    "test_df  = pd.read_csv(os.path.join(BASE, \"test.tsv\"),       sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Wir brauchen die Spalten:\n",
    "#   TRB_CDR3, Epitope, Binding, task\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df[\"Binding\"] = df[\"Binding\"].astype(int)   # Bindungs‐Label\n",
    "    df[\"task\"]    = df[\"task\"].astype(str)      # TPP1…TPP4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69e9a3-df2a-4b9b-9916-1dfe87d7da90",
   "metadata": {},
   "source": [
    "2) Funktion, um aus einem HDF5 pro Sequenz die Embeddings zu ziehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeba8670-c27e-4be2-bf1c-af2fa17e1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_emb_dict(h5path):\n",
    "    \"\"\"\n",
    "    Liest ein HDF5 ein und gibt ein Dict zurück:\n",
    "      { sequence_string: np.array([...]) }\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    with h5py.File(h5path, \"r\") as hf:\n",
    "        for seq in hf.keys():\n",
    "            # jedes seq ist ein Dataset-Name, hf[seq][:] gibt die Vektoren\n",
    "            d[seq] = hf[seq][:]  \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb900f9-e1f9-40c5-83b2-fb7482716c4e",
   "metadata": {},
   "source": [
    "3) Die Dictionaries für TCR und Epitope laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83950870-6355-4c01-9754-434392c7d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR = \"../../../../data/embeddings/beta/allele/dimension_1024\"\n",
    "\n",
    "# Passe die Dateinamen auf Deine an:\n",
    "tcr_train_dict = load_emb_dict(os.path.join(EMB_DIR, \"padded_train_tcr_embeddings_final.h5\"))\n",
    "epi_train_dict = load_emb_dict(os.path.join(EMB_DIR, \"padded_train_epitope_embeddings_final.h5\"))\n",
    "\n",
    "tcr_val_dict   = load_emb_dict(os.path.join(EMB_DIR, \"padded_valid_tcr_embeddings_final.h5\"))\n",
    "epi_val_dict   = load_emb_dict(os.path.join(EMB_DIR, \"padded_valid_epitope_embeddings_final.h5\"))\n",
    "\n",
    "tcr_test_dict  = load_emb_dict(os.path.join(EMB_DIR, \"padded_test_tcr_embeddings_final.h5\"))\n",
    "epi_test_dict  = load_emb_dict(os.path.join(EMB_DIR, \"padded_test_epitope_embeddings_final.h5\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bec093-3ca8-443b-8596-2beb7ec73df6",
   "metadata": {},
   "source": [
    "4) Feature-Matrizen bauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8d216-06b4-475c-9aac-3a743dbdb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def build_feature_matrix(df, tcr_dict, epi_dict, emb_dim=1024):\n",
    "    \"\"\"\n",
    "    Für jeden Eintrag in df:\n",
    "      - hole tcr_dict[TRB_CDR3]  (oder Null‐Vektor)\n",
    "      - hole epi_dict[Epitope]   (oder Null‐Vektor)\n",
    "    und concatenatiere zu einem 2*emb_dim‐Vektor.\n",
    "    \"\"\"\n",
    "    X = np.zeros((len(df), emb_dim*2), dtype=float)\n",
    "    for i, row in enumerate(tqdm(df.itertuples(), total=len(df))):\n",
    "        seq_tcr = row.TRB_CDR3\n",
    "        seq_epi = row.Epitope\n",
    "        v_tcr = tcr_dict.get(seq_tcr, np.zeros(emb_dim))\n",
    "        v_epi = epi_dict.get(seq_epi, np.zeros(emb_dim))\n",
    "        X[i,:emb_dim]      = v_tcr\n",
    "        X[i,emb_dim:emb_dim*2] = v_epi\n",
    "    return X\n",
    "\n",
    "# Train/Val zusammen zum Training\n",
    "trainval_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "\n",
    "X_tr = build_feature_matrix(trainval_df, tcr_train_dict, epi_train_dict)\n",
    "X_te = build_feature_matrix(test_df,      tcr_test_dict,  epi_test_dict)\n",
    "\n",
    "# Labels: mappe TPP1→0, TPP2→1, TPP3→2, TPP4→3\n",
    "label_map = {\"TPP1\":0, \"TPP2\":1, \"TPP3\":2, \"TPP4\":3}\n",
    "y_tr = trainval_df[\"task\"].map(label_map).values\n",
    "y_te = test_df[\"task\"].map(label_map).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73457e-6001-4092-8f74-b6a650eae563",
   "metadata": {},
   "source": [
    "5) Random Forest für vier Klassen trainieren und evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e874a0f-0638-4b40-b998-a8dcdbc81c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics  import classification_report, confusion_matrix\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",  # gleicht ungleiche Klassenmengen aus\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = rf.predict(X_te)\n",
    "print(\"=== Classification Report (TPP1–TPP4) auf Test-Set ===\")\n",
    "print(classification_report(y_te, y_pred, target_names=[\"TPP1\",\"TPP2\",\"TPP3\",\"TPP4\"]))\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "cm = confusion_matrix(y_te, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2864b-9f71-43a4-87ca-5723387732a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f10ba-28a9-4b98-8057-dc92eece939e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

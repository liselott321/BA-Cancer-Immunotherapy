{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8838a-8ea6-4e2f-862a-e9fcede10484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c85211-ea01-468f-a542-716482a9d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"VDJdb_beta\": vdjdb_beta_read_path,\n",
    "    \"McPAS_beta\": mcpastcr_beta_read_path,\n",
    "    \"IEDB_beta\": iedb_beta_read_path,\n",
    "    \"pMTnet_beta\": pmtnet_beta_read_path,\n",
    "    \"VDJdb_paired\": vdjdb_paired_read_path,\n",
    "    \"McPAS_paired\": mcpastcr_paired_read_path,\n",
    "    \"IEDB_paired\": iedb_paired_read_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13e8d3-eb17-4835-a243-e9c3744b4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Berechnung der TPP-Kategorien pro Datei (vom classification File Ã¼bernommen: data_scripts/data_preparation/classification.ipynb)\n",
    "def calculate_task(row, known_epitopes, known_tcrs, paired):\n",
    "    \"\"\"Weist TPP1-4 basierend auf bekannten Epitope & TCRs zu.\"\"\"\n",
    "    if paired:\n",
    "        tra_cdr3 = str(row['TRA_CDR3']) if pd.notna(row['TRA_CDR3']) else ''\n",
    "        trb_cdr3 = str(row['TRB_CDR3']) if pd.notna(row['TRB_CDR3']) else ''\n",
    "        tcr = tra_cdr3 + '_' + trb_cdr3\n",
    "    else:\n",
    "        tcr = row['TRB_CDR3']\n",
    "\n",
    "    epitope_exists = row['Epitope'] in known_epitopes\n",
    "    cdr3_exists = tcr in known_tcrs\n",
    "\n",
    "    if epitope_exists and cdr3_exists:\n",
    "        return 'TPP1'\n",
    "    elif epitope_exists and not cdr3_exists:\n",
    "        return 'TPP2'\n",
    "    elif not epitope_exists and not cdr3_exists:\n",
    "        return 'TPP3'\n",
    "    elif not epitope_exists and cdr3_exists:\n",
    "        return 'TPP4'\n",
    "    else:\n",
    "        return 'Unknown'  # Falls etwas schiefgeht\n",
    "\n",
    "# Durch alle Dateien iterieren und analysieren\n",
    "for file_name, path in file_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "            \n",
    "            required_columns = {\"TRB_CDR3\", \"Epitope\"}\n",
    "            if \"TRA_CDR3\" in df.columns:\n",
    "                paired = True\n",
    "            else:\n",
    "                paired = False\n",
    "            \n",
    "            missing_columns = required_columns - set(df.columns)\n",
    "            if missing_columns:\n",
    "                print(f\"Fehlende Spalten in {file_name}: {missing_columns}\")\n",
    "                continue\n",
    "\n",
    "            if paired:\n",
    "                df[\"tcr_key\"] = df['TRA_CDR3'].astype(str) + '_' + df['TRB_CDR3'].astype(str)\n",
    "            else:\n",
    "                df[\"tcr_key\"] = df['TRB_CDR3']\n",
    "\n",
    "            # Berechnung der TCR- und Epitope-Statistiken\n",
    "            distinct_tcrs = df[\"tcr_key\"].nunique()\n",
    "            unique_tcrs = df[df.duplicated(subset=[\"tcr_key\"], keep=False) == False][\"tcr_key\"].count()\n",
    "            distinct_epitopes = df[\"Epitope\"].nunique()\n",
    "            unique_epitopes = df[df.duplicated(subset=[\"Epitope\"], keep=False) == False][\"Epitope\"].count()\n",
    "\n",
    "            # Identifikation von bekannten Epitope und TCRs innerhalb der Datei selbst\n",
    "            seen_epitopes = set(df[\"Epitope\"].dropna())\n",
    "            seen_tcrs = set(df[\"tcr_key\"].dropna())\n",
    "\n",
    "            df[\"task\"] = df.apply(lambda x: calculate_task(x, seen_epitopes, seen_tcrs, paired), axis=1)\n",
    "            tpp_counts = df[\"task\"].value_counts().to_dict()\n",
    "            tpp1_count = tpp_counts.get(\"TPP1\", 0)\n",
    "            tpp2_count = tpp_counts.get(\"TPP2\", 0)\n",
    "            tpp3_count = tpp_counts.get(\"TPP3\", 0)\n",
    "            tpp4_count = tpp_counts.get(\"TPP4\", 0)\n",
    "\n",
    "            print(f\"**{file_name}**\")\n",
    "            print(f\"  - Distinct TCRs: {distinct_tcrs}\")\n",
    "            print(f\"  - Unique TCRs: {unique_tcrs}\")\n",
    "            print(f\"  - Distinct Epitopes: {distinct_epitopes}\")\n",
    "            print(f\"  - Unique Epitopes: {unique_epitopes}\")\n",
    "            '''print(f\"  - TPP1: {tpp1_count}\")\n",
    "            print(f\"  - TPP2: {tpp2_count}\")\n",
    "            print(f\"  - TPP3: {tpp3_count}\")\n",
    "            print(f\"  - TPP4: {tpp4_count}\\n\")'''\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten der Datei {file_name}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Datei nicht gefunden: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

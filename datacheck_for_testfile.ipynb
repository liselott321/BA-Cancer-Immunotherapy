{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8838a-8ea6-4e2f-862a-e9fcede10484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c85211-ea01-468f-a542-716482a9d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"VDJdb_beta\": vdjdb_beta_read_path,\n",
    "    \"McPAS_beta\": mcpastcr_beta_read_path,\n",
    "    \"IEDB_beta\": iedb_beta_read_path,\n",
    "    \"pMTnet_beta\": pmtnet_beta_read_path,\n",
    "    \"VDJdb_paired\": vdjdb_paired_read_path,\n",
    "    \"McPAS_paired\": mcpastcr_paired_read_path,\n",
    "    \"IEDB_paired\": iedb_paired_read_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387222f1-411e-46bf-91da-afd9682cb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to classify tasks based on TCR and epitope presence\n",
    "def calculate_task(row, known_epitopes, known_tcr, paired=False):\n",
    "    if paired:\n",
    "        tra_cdr3 = str(row['TRA_CDR3']) if pd.notna(row['TRA_CDR3']) else ''\n",
    "        trb_cdr3 = str(row['TRB_CDR3']) if pd.notna(row['TRB_CDR3']) else ''\n",
    "        tcr = tra_cdr3 + '_' + trb_cdr3\n",
    "    else:\n",
    "        tcr = row['TRB_CDR3']\n",
    "    \n",
    "    epitope_exists = row['Epitope'] in known_epitopes\n",
    "    cdr3_exists = tcr in known_tcr\n",
    "    \n",
    "    if epitope_exists and cdr3_exists:\n",
    "        return 'TPP1'\n",
    "    elif epitope_exists and not cdr3_exists:\n",
    "        return 'TPP2'\n",
    "    elif not epitope_exists and not cdr3_exists:\n",
    "        return 'TPP3'\n",
    "    elif not epitope_exists and cdr3_exists:\n",
    "        return 'TPP4'\n",
    "    raise Exception(\"Something seems wrong\")\n",
    "\n",
    "# Placeholder for the data\n",
    "all_data = {}\n",
    "\n",
    "# Load and prepare data\n",
    "for file_name, path in file_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "\n",
    "            # Create tcr_key\n",
    "            if \"TRA_CDR3\" in df.columns:\n",
    "                paired = True\n",
    "                df[\"tcr_key\"] = df[\"TRA_CDR3\"].astype(str) + '_' + df[\"TRB_CDR3\"]\n",
    "            else:\n",
    "                paired = False\n",
    "                df[\"tcr_key\"] = df[\"TRB_CDR3\"]\n",
    "\n",
    "            all_data[file_name] = df\n",
    "            print(f\"{file_name} geladen mit {len(df)} Einträgen.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten der Datei {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Datei nicht gefunden: {file_name}\")\n",
    "\n",
    "# Analyse: Classify TPP tasks\n",
    "for test_file_name, test_df in all_data.items():\n",
    "    # Define training data (excluding the current test set)\n",
    "    train_df = pd.concat([data for name, data in all_data.items() if name != test_file_name]).drop_duplicates()\n",
    "\n",
    "    seen_tcrs = set(train_df[\"tcr_key\"])\n",
    "    seen_epitopes = set(train_df[\"Epitope\"])\n",
    "\n",
    "    # Determine if it's a paired dataset\n",
    "    paired = \"TRA_CDR3\" in test_df.columns\n",
    "\n",
    "    # Apply classification\n",
    "    test_df['task'] = test_df.apply(lambda row: calculate_task(row, seen_epitopes, seen_tcrs, paired=paired), axis=1)\n",
    "\n",
    "    # Count TPP3 pairs\n",
    "    tpp3_pairs = (test_df['task'] == 'TPP3').sum()\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"\\n**Wenn {test_file_name} als Testset verwendet wird:**\")\n",
    "    print(f\"  - TPP3-Paare im Testset: {tpp3_pairs}\")\n",
    "    print(f\"  - Gesamt Test-Paare: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05921807-1831-40e1-8fec-66332de4a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to classify TPP tasks based on TCR and epitope presence\n",
    "def calculate_task(row, known_epitopes, known_tcr, paired=False):\n",
    "    if paired:\n",
    "        tra_cdr3 = str(row['TRA_CDR3']) if pd.notna(row['TRA_CDR3']) else ''\n",
    "        trb_cdr3 = str(row['TRB_CDR3']) if pd.notna(row['TRB_CDR3']) else ''\n",
    "        tcr = tra_cdr3 + '_' + trb_cdr3\n",
    "    else:\n",
    "        tcr = row['TRB_CDR3']\n",
    "    \n",
    "    epitope_exists = row['Epitope'] in known_epitopes\n",
    "    cdr3_exists = tcr in known_tcr\n",
    "    \n",
    "    if epitope_exists and cdr3_exists:\n",
    "        return 'TPP1'\n",
    "    elif epitope_exists and not cdr3_exists:\n",
    "        return 'TPP2'\n",
    "    elif not epitope_exists and not cdr3_exists:\n",
    "        return 'TPP3'\n",
    "    elif not epitope_exists and cdr3_exists:\n",
    "        return 'TPP4'\n",
    "    raise Exception(\"Something seems wrong\")\n",
    "\n",
    "\n",
    "# Load train and validation data\n",
    "train_file = f'{pipeline_data_splitted}/{precision}/beta/train.tsv'\n",
    "validation_file = f'{pipeline_data_splitted}/{precision}/beta/validation.tsv'\n",
    "test_file = f'{pipeline_data_splitted}/{precision}/beta/test.tsv'\n",
    "vdjdb_test_file = vdjdb_beta_read_path  # Path to the VDJdb test dataset\n",
    "\n",
    "df_train = pd.read_csv(train_file, sep='\\t')\n",
    "df_validation = pd.read_csv(validation_file, sep='\\t')\n",
    "df_test = pd.read_csv(test_file, sep='\\t')\n",
    "\n",
    "# Combine train and validation datasets\n",
    "trainval_df = pd.concat([df_train, df_validation], ignore_index=True)\n",
    "\n",
    "# Load VDJdb test data\n",
    "vdjdb_df = pd.read_csv(vdjdb_test_file, sep='\\t') #f'{pipeline_data_cleaned}/VDJdb/VDJdb_cleaned_data_beta.tsv'\n",
    "\n",
    "# Create tcr_key and clean data\n",
    "trainval_df[\"tcr_key\"] = trainval_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "trainval_df[\"Epitope\"] = trainval_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "vdjdb_df[\"tcr_key\"] = vdjdb_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "vdjdb_df[\"Epitope\"] = vdjdb_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "df_test[\"tcr_key\"] = df_test[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "df_test[\"Epitope\"] = df_test[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "# Generate lookup sets for fast comparison\n",
    "seen_tcrs = set(trainval_df[\"tcr_key\"])\n",
    "seen_epitopes = set(trainval_df[\"Epitope\"])\n",
    "\n",
    "# Apply classification to the VDJdb dataset\n",
    "vdjdb_df['task'] = vdjdb_df.apply(lambda row: calculate_task(row, seen_epitopes, seen_tcrs, paired=False), axis=1)\n",
    "\n",
    "# Count TPP3 pairs\n",
    "tpp3_pairs = (vdjdb_df['task'] == 'TPP3').sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n**TPP Analysis for VDJdb with Train + Validation**\")\n",
    "print(f\"  - TPP3-Paare im Testset: {tpp3_pairs}\")\n",
    "print(f\"  - Gesamt Test-Paare: {len(vdjdb_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f78f3-8952-4f5d-b888-d1e88adef63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original TPP3 Paare vor dem Hinzufügen negativer Daten\n",
    "original_tpp3 = vdjdb_df[(vdjdb_df['task'] == 'TPP3')][[\"tcr_key\", \"Epitope\"]]\n",
    "\n",
    "# Prüfen, ob diese TPP3-Paare in den negativen Daten des Train/Validation-Sets auftauchen\n",
    "negative_in_trainval = trainval_df[trainval_df['Binding'] == 0][[\"tcr_key\", \"Epitope\"]]\n",
    "\n",
    "# Vergleichen\n",
    "tpp3_now_seen = original_tpp3.merge(negative_in_trainval, on=[\"tcr_key\", \"Epitope\"], how=\"inner\")\n",
    "\n",
    "print(f\"Anzahl der ursprünglichen TPP3-Paare, die jetzt in negativen Daten des Train/Validation-Sets vorkommen: {len(tpp3_now_seen)}\")\n",
    "\n",
    "# Zeige einige Beispiele\n",
    "if not tpp3_now_seen.empty:\n",
    "    print(tpp3_now_seen.head(10))\n",
    "else:\n",
    "    print(\"Keine der ursprünglichen TPP3-Paare wurden in den negativen Daten gefunden.\")\n",
    "\n",
    "# Prüfen, ob die ursprünglichen TPP3-Paare in den positiven Daten des Train/Validation-Sets enthalten sind\n",
    "positive_in_trainval = trainval_df[trainval_df['Binding'] == 1][[\"tcr_key\", \"Epitope\"]]\n",
    "\n",
    "# Vergleich durchführen\n",
    "tpp3_in_pos_trainval = original_tpp3.merge(positive_in_trainval, on=[\"tcr_key\", \"Epitope\"], how=\"inner\")\n",
    "\n",
    "print(f\"Anzahl der ursprünglichen TPP3-Paare, die jetzt in den positiven Train/Validation-Daten vorkommen: {len(tpp3_in_pos_trainval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf564727-b7ff-4151-aa61-917733fc5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the concatenated files\n",
    "concatenated_beta_file = f'{pipeline_data_concatenated}/{precision}/beta_concatenated.tsv'\n",
    "vdjdb_test_file = vdjdb_beta_read_path  # Path to the original VDJdb data\n",
    "\n",
    "# Load concatenated beta data\n",
    "concatenated_beta_df = pd.read_csv(concatenated_beta_file, sep='\\t')\n",
    "\n",
    "# Load original VDJdb dataset\n",
    "vdjdb_df = pd.read_csv(vdjdb_test_file, sep='\\t')\n",
    "\n",
    "# Create tcr_key and clean data\n",
    "concatenated_beta_df[\"tcr_key\"] = concatenated_beta_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "concatenated_beta_df[\"Epitope\"] = concatenated_beta_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "vdjdb_df[\"tcr_key\"] = vdjdb_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "vdjdb_df[\"Epitope\"] = vdjdb_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "# Generate lookup sets from concatenated data\n",
    "seen_tcrs = set(concatenated_beta_df[\"tcr_key\"])\n",
    "seen_epitopes = set(concatenated_beta_df[\"Epitope\"])\n",
    "\n",
    "# Apply classification to the VDJdb dataset\n",
    "vdjdb_df['task'] = vdjdb_df.apply(lambda row: calculate_task(row, seen_epitopes, seen_tcrs, paired=False), axis=1)\n",
    "\n",
    "# Count TPP3 pairs\n",
    "tpp3_pairs = (vdjdb_df['task'] == 'TPP3').sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n**TPP Analysis for VDJdb with Concatenated Beta Data**\")\n",
    "print(f\"  - TPP3-Paare im Testset: {tpp3_pairs}\")\n",
    "print(f\"  - Gesamt Test-Paare: {len(vdjdb_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2cae14-7f9e-4202-898e-1c099bc786f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Daten aus Train/Validation\n",
    "negative_in_trainval = trainval_df[trainval_df['Binding'] == 0][[\"tcr_key\", \"Epitope\"]]\n",
    "negative_in_test = df_test[df_test['Binding'] == 0][[\"tcr_key\", \"Epitope\"]]\n",
    "\n",
    "# Prüfen, ob VDJdb-TCRs in den negativen Daten vorkommen\n",
    "tpp3_tcr_overlap = vdjdb_df[~vdjdb_df['tcr_key'].isin(seen_tcrs) & vdjdb_df['tcr_key'].isin(set(negative_in_trainval['tcr_key']))]\n",
    "tpp3_tcr_overlap_test = vdjdb_df[~vdjdb_df['tcr_key'].isin(seen_tcrs) & vdjdb_df['tcr_key'].isin(set(negative_in_test['tcr_key']))]\n",
    "\n",
    "# Prüfen, ob VDJdb-Epitope in den negativen Daten vorkommen\n",
    "tpp3_epitope_overlap = vdjdb_df[~vdjdb_df['Epitope'].isin(seen_epitopes) & vdjdb_df['Epitope'].isin(set(negative_in_trainval['Epitope']))]\n",
    "tpp3_epitope_overlap_test = vdjdb_df[~vdjdb_df['Epitope'].isin(seen_epitopes) & vdjdb_df['Epitope'].isin(set(negative_in_trainval['Epitope']))]\n",
    "\n",
    "print(f\"VDJdb TPP3-Paare, deren TCR jetzt in negativen Daten aus Train/Validation vorkommt: {len(tpp3_tcr_overlap)}\")\n",
    "print(f\"VDJdb TPP3-Paare, deren Epitope jetzt in negativen Daten aus Train/Validation vorkommt: {len(tpp3_epitope_overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545d6e5-a0de-494e-b378-0183b28d879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VDJdb test data\n",
    "vdjdb_df = pd.read_csv(vdjdb_test_file, sep='\\t') #f'{pipeline_data_cleaned}/VDJdb/VDJdb_cleaned_data_beta.tsv'\n",
    "vdjdb_df[\"tcr_key\"] = vdjdb_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "vdjdb_df[\"Epitope\"] = vdjdb_df[\"Epitope\"].astype(str).str.strip()\n",
    "vdjdb_df['task'] = vdjdb_df.apply(lambda row: calculate_task(row, seen_epitopes, seen_tcrs, paired=False), axis=1)\n",
    "# TPP3-Paare aus dem vdjdb File\n",
    "original_tpp3 = vdjdb_df[vdjdb_df['task'] == 'TPP3'][[\"tcr_key\", \"Epitope\"]]\n",
    "# Prüfen, ob diese TPP3-Paare im finalen Testset noch vorhanden sind\n",
    "tpp3_in_test = original_tpp3.merge(df_test, on=[\"tcr_key\", \"Epitope\"], how=\"inner\")\n",
    "print(f\"TPP3-Paare von cleaned data, die noch im finalen Testset vorhanden sind: {len(tpp3_in_test)}\")\n",
    "\n",
    "# Prüfen, welche TPP-Klasse die TPP3-Paare jetzt im finalen Testset haben\n",
    "tpp3_in_test_with_task = original_tpp3.merge(df_test, on=[\"tcr_key\", \"Epitope\"], how=\"inner\")\n",
    "\n",
    "# Zählen, wie viele der ursprünglichen TPP3-Paare jetzt welcher TPP-Klasse zugeordnet wurden\n",
    "task_distribution = tpp3_in_test_with_task['task'].value_counts()\n",
    "\n",
    "print(f\"\\n✅ TPP3-Paare von cleaned data, die noch im finalen Testset vorhanden sind: {len(tpp3_in_test_with_task)}\")\n",
    "print(f\"🔄 Aktuelle TPP-Klassen dieser Paare im finalen Testset:\")\n",
    "print(task_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddd1bd-445f-4e27-8894-79fa3345c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen, ob TCRs in negativen Daten des Train/Validation-Sets vorkommen\n",
    "tcrs_in_negative_trainval = original_tpp3[original_tpp3['tcr_key'].isin(trainval_df[trainval_df['Binding'] == 0]['tcr_key'])]\n",
    "\n",
    "# Prüfen, ob Epitope in negativen Daten des Train/Validation-Sets vorkommen\n",
    "epitopes_in_negative_trainval = original_tpp3[original_tpp3['Epitope'].isin(trainval_df[trainval_df['Binding'] == 0]['Epitope'])]\n",
    "\n",
    "print(f\"⚠️ Anzahl TPP3-Paare, deren TCRs in den negativen Train/Validation-Daten vorkommen: {len(tcrs_in_negative_trainval)}\")\n",
    "print(f\"⚠️ Anzahl TPP3-Paare, deren Epitope in den negativen Train/Validation-Daten vorkommen: {len(epitopes_in_negative_trainval)}\")\n",
    "\n",
    "# Prüfen, ob TCRs in den positiven Daten vorkommen\n",
    "tcrs_in_positive_trainval = original_tpp3[original_tpp3['tcr_key'].isin(trainval_df[trainval_df['Binding'] == 1]['tcr_key'])]\n",
    "\n",
    "# Prüfen, ob Epitope in den positiven Daten vorkommen\n",
    "epitopes_in_positive_trainval = original_tpp3[original_tpp3['Epitope'].isin(trainval_df[trainval_df['Binding'] == 1]['Epitope'])]\n",
    "\n",
    "print(f\"✅ Anzahl TPP3-Paare, deren TCRs in den positiven Train/Validation-Daten vorkommen: {len(tcrs_in_positive_trainval)}\")\n",
    "print(f\"✅ Anzahl TPP3-Paare, deren Epitope in den positiven Train/Validation-Daten vorkommen: {len(epitopes_in_positive_trainval)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

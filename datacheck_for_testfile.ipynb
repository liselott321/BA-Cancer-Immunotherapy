{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8838a-8ea6-4e2f-862a-e9fcede10484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c85211-ea01-468f-a542-716482a9d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {\n",
    "    \"VDJdb_beta\": vdjdb_beta_read_path,\n",
    "    \"McPAS_beta\": mcpastcr_beta_read_path,\n",
    "    \"IEDB_beta\": iedb_beta_read_path,\n",
    "    \"pMTnet_beta\": pmtnet_beta_read_path,\n",
    "    \"VDJdb_paired\": vdjdb_paired_read_path,\n",
    "    \"McPAS_paired\": mcpastcr_paired_read_path,\n",
    "    \"IEDB_paired\": iedb_paired_read_path\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a5f73-5337-4575-bee1-b4ec20eb1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Daten speichern\n",
    "all_data = {}\n",
    "\n",
    "# Daten einlesen und vorbereiten\n",
    "for file_name, path in file_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "\n",
    "            # tcr_key erstellen\n",
    "            if \"TRA_CDR3\" in df.columns:\n",
    "                df[\"tcr_key\"] = df[\"TRA_CDR3\"].astype(str) + '_' + df[\"TRB_CDR3\"]\n",
    "            else:\n",
    "                df[\"tcr_key\"] = df[\"TRB_CDR3\"]\n",
    "\n",
    "            all_data[file_name] = df[[\"tcr_key\", \"Epitope\"]].drop_duplicates()\n",
    "\n",
    "            print(f\"{file_name} geladen mit {len(df)} Einträgen.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten der Datei {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Datei nicht gefunden: {file_name}\")\n",
    "\n",
    "# Analyse: Welcher Datensatz sollte im Testset sein?\n",
    "for test_file_name, test_df in all_data.items():\n",
    "    # Alle anderen Daten als Trainingsset\n",
    "    train_df = pd.concat([data for name, data in all_data.items() if name != test_file_name]).drop_duplicates()\n",
    "\n",
    "    # Erstelle Sets für schnelles Lookup\n",
    "    seen_tcrs = set(train_df[\"tcr_key\"])\n",
    "    seen_epitopes = set(train_df[\"Epitope\"])\n",
    "\n",
    "    # TPP3-Definition: Weder TCR noch Epitope wurden im Trainingsset gesehen\n",
    "    tpp3_pairs = test_df[~test_df[\"tcr_key\"].isin(seen_tcrs) & ~test_df[\"Epitope\"].isin(seen_epitopes)]\n",
    "\n",
    "    # Ausgabe der Ergebnisse\n",
    "    print(f\"\\n**Wenn {test_file_name} als Testset verwendet wird:**\")\n",
    "    print(f\"  - TPP3-Paare im Testset: {len(tpp3_pairs)}\")\n",
    "    print(f\"  - Gesamt Test-Paare: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d4186e-69d6-453c-9c14-00fc50b9cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "beta_train_file = f'{pipeline_data_splitted}/{precision}/beta/train.tsv'\n",
    "beta_validation_file = f'{pipeline_data_splitted}/{precision}/beta/validation.tsv'\n",
    "vdjdb_test_file = vdjdb_beta_read_path  # Path to the original VDJdb data\n",
    "\n",
    "# Load train and validation data\n",
    "df_train = pd.read_csv(beta_train_file, sep='\\t')\n",
    "df_validation = pd.read_csv(beta_validation_file, sep='\\t')\n",
    "\n",
    "# Concatenate train and validation for analysis\n",
    "trainval_df = pd.concat([df_train, df_validation], ignore_index=True)\n",
    "\n",
    "# Load VDJdb dataset\n",
    "vdjdb_df = pd.read_csv(vdjdb_test_file, sep='\\t')\n",
    "\n",
    "# Prepare the data by creating tcr_key and ensuring clean values\n",
    "trainval_df[\"tcr_key\"] = trainval_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "trainval_df[\"Epitope\"] = trainval_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "vdjdb_df[\"tcr_key\"] = vdjdb_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "vdjdb_df[\"Epitope\"] = vdjdb_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "# Create lookup sets from train+validation data\n",
    "seen_tcrs = set(trainval_df[\"tcr_key\"])\n",
    "seen_epitopes = set(trainval_df[\"Epitope\"])\n",
    "\n",
    "# Identify TPP3 pairs in VDJdb (where both TCR and Epitope are unseen)\n",
    "tpp3_pairs = vdjdb_df[~vdjdb_df[\"tcr_key\"].isin(seen_tcrs) & ~vdjdb_df[\"Epitope\"].isin(seen_epitopes)]\n",
    "\n",
    "# Print the result\n",
    "print(f\"\\n**TPP3 Analysis for VDJdb in Train + Validation**\")\n",
    "print(f\"  - TPP3-Paare im Testset: {len(tpp3_pairs)}\")\n",
    "print(f\"  - Gesamt Test-Paare: {len(vdjdb_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387222f1-411e-46bf-91da-afd9682cb8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to classify tasks based on TCR and epitope presence\n",
    "def calculate_task(row, known_epitopes, known_tcr, paired=False):\n",
    "    if paired:\n",
    "        tra_cdr3 = str(row['TRA_CDR3']) if pd.notna(row['TRA_CDR3']) else ''\n",
    "        trb_cdr3 = str(row['TRB_CDR3']) if pd.notna(row['TRB_CDR3']) else ''\n",
    "        tcr = tra_cdr3 + '_' + trb_cdr3\n",
    "    else:\n",
    "        tcr = row['TRB_CDR3']\n",
    "    \n",
    "    epitope_exists = row['Epitope'] in known_epitopes\n",
    "    cdr3_exists = tcr in known_tcr\n",
    "    \n",
    "    if epitope_exists and cdr3_exists:\n",
    "        return 'TPP1'\n",
    "    elif epitope_exists and not cdr3_exists:\n",
    "        return 'TPP2'\n",
    "    elif not epitope_exists and not cdr3_exists:\n",
    "        return 'TPP3'\n",
    "    elif not epitope_exists and cdr3_exists:\n",
    "        return 'TPP4'\n",
    "    raise Exception(\"Something seems wrong\")\n",
    "\n",
    "# Placeholder for the data\n",
    "all_data = {}\n",
    "\n",
    "# Load and prepare data\n",
    "for file_name, path in file_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "\n",
    "            # Create tcr_key\n",
    "            if \"TRA_CDR3\" in df.columns:\n",
    "                paired = True\n",
    "                df[\"tcr_key\"] = df[\"TRA_CDR3\"].astype(str) + '_' + df[\"TRB_CDR3\"]\n",
    "            else:\n",
    "                paired = False\n",
    "                df[\"tcr_key\"] = df[\"TRB_CDR3\"]\n",
    "\n",
    "            all_data[file_name] = df\n",
    "            print(f\"{file_name} geladen mit {len(df)} Einträgen.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten der Datei {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Datei nicht gefunden: {file_name}\")\n",
    "\n",
    "# Analyse: Classify TPP tasks\n",
    "for test_file_name, test_df in all_data.items():\n",
    "    # Define training data (excluding the current test set)\n",
    "    train_df = pd.concat([data for name, data in all_data.items() if name != test_file_name]).drop_duplicates()\n",
    "\n",
    "    seen_tcrs = set(train_df[\"tcr_key\"])\n",
    "    seen_epitopes = set(train_df[\"Epitope\"])\n",
    "\n",
    "    # Determine if it's a paired dataset\n",
    "    paired = \"TRA_CDR3\" in test_df.columns\n",
    "\n",
    "    # Apply classification\n",
    "    test_df['task'] = test_df.apply(lambda row: calculate_task(row, seen_epitopes, seen_tcrs, paired=paired), axis=1)\n",
    "\n",
    "    # Count TPP3 pairs\n",
    "    tpp3_pairs = (test_df['task'] == 'TPP3').sum()\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"\\n**Wenn {test_file_name} als Testset verwendet wird:**\")\n",
    "    print(f\"  - TPP3-Paare im Testset: {tpp3_pairs}\")\n",
    "    print(f\"  - Gesamt Test-Paare: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05921807-1831-40e1-8fec-66332de4a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to classify TPP tasks based on TCR and epitope presence\n",
    "def calculate_task(row, known_epitopes, known_tcr, paired=False):\n",
    "    if paired:\n",
    "        tra_cdr3 = str(row['TRA_CDR3']) if pd.notna(row['TRA_CDR3']) else ''\n",
    "        trb_cdr3 = str(row['TRB_CDR3']) if pd.notna(row['TRB_CDR3']) else ''\n",
    "        tcr = tra_cdr3 + '_' + trb_cdr3\n",
    "    else:\n",
    "        tcr = row['TRB_CDR3']\n",
    "    \n",
    "    epitope_exists = row['Epitope'] in known_epitopes\n",
    "    cdr3_exists = tcr in known_tcr\n",
    "    \n",
    "    if epitope_exists and cdr3_exists:\n",
    "        return 'TPP1'\n",
    "    elif epitope_exists and not cdr3_exists:\n",
    "        return 'TPP2'\n",
    "    elif not epitope_exists and not cdr3_exists:\n",
    "        return 'TPP3'\n",
    "    elif not epitope_exists and cdr3_exists:\n",
    "        return 'TPP4'\n",
    "    raise Exception(\"Something seems wrong\")\n",
    "\n",
    "\n",
    "# Load train and validation data\n",
    "train_file = f'{pipeline_data_splitted}/{precision}/beta/train.tsv'\n",
    "validation_file = f'{pipeline_data_splitted}/{precision}/beta/validation.tsv'\n",
    "vdjdb_test_file = vdjdb_beta_read_path  # Path to the VDJdb test dataset\n",
    "\n",
    "df_train = pd.read_csv(train_file, sep='\\t')\n",
    "df_validation = pd.read_csv(validation_file, sep='\\t')\n",
    "\n",
    "# Combine train and validation datasets\n",
    "trainval_df = pd.concat([df_train, df_validation], ignore_index=True)\n",
    "\n",
    "# Load VDJdb test data\n",
    "vdjdb_df = pd.read_csv(vdjdb_test_file, sep='\\t')\n",
    "\n",
    "# Create tcr_key and clean data\n",
    "trainval_df[\"tcr_key\"] = trainval_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "trainval_df[\"Epitope\"] = trainval_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "vdjdb_df[\"tcr_key\"] = vdjdb_df[\"TRB_CDR3\"].astype(str).str.strip()\n",
    "vdjdb_df[\"Epitope\"] = vdjdb_df[\"Epitope\"].astype(str).str.strip()\n",
    "\n",
    "# Generate lookup sets for fast comparison\n",
    "seen_tcrs = set(trainval_df[\"tcr_key\"])\n",
    "seen_epitopes = set(trainval_df[\"Epitope\"])\n",
    "\n",
    "# Apply classification to the VDJdb dataset\n",
    "vdjdb_df['task'] = vdjdb_df.apply(lambda row: calculate_task(row, seen_epitopes, seen_tcrs, paired=False), axis=1)\n",
    "\n",
    "# Count TPP3 pairs\n",
    "tpp3_pairs = (vdjdb_df['task'] == 'TPP3').sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n**TPP Analysis for VDJdb with Train + Validation**\")\n",
    "print(f\"  - TPP3-Paare im Testset: {tpp3_pairs}\")\n",
    "print(f\"  - Gesamt Test-Paare: {len(vdjdb_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f78f3-8952-4f5d-b888-d1e88adef63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original TPP3 Paare vor dem Hinzufügen negativer Daten\n",
    "original_tpp3 = vdjdb_df[(vdjdb_df['task'] == 'TPP3')][[\"tcr_key\", \"Epitope\"]]\n",
    "\n",
    "# Prüfen, ob diese TPP3-Paare in den negativen Daten des Train/Validation-Sets auftauchen\n",
    "negative_in_trainval = trainval_df[trainval_df['Binding'] == 0][[\"tcr_key\", \"Epitope\"]]\n",
    "\n",
    "# Vergleichen\n",
    "tpp3_now_seen = original_tpp3.merge(negative_in_trainval, on=[\"tcr_key\", \"Epitope\"], how=\"inner\")\n",
    "\n",
    "print(f\"Anzahl der ursprünglichen TPP3-Paare, die jetzt in negativen Daten des Train/Validation-Sets vorkommen: {len(tpp3_now_seen)}\")\n",
    "\n",
    "# Zeige einige Beispiele\n",
    "if not tpp3_now_seen.empty:\n",
    "    print(tpp3_now_seen.head(10))\n",
    "else:\n",
    "    print(\"Keine der ursprünglichen TPP3-Paare wurden in den negativen Daten gefunden.\")\n",
    "\n",
    "# Prüfen, ob die ursprünglichen TPP3-Paare in den positiven Daten des Train/Validation-Sets enthalten sind\n",
    "positive_in_trainval = trainval_df[trainval_df['Binding'] == 1][[\"tcr_key\", \"Epitope\"]]\n",
    "\n",
    "# Vergleich durchführen\n",
    "tpp3_in_pos_trainval = original_tpp3.merge(positive_in_trainval, on=[\"tcr_key\", \"Epitope\"], how=\"inner\")\n",
    "\n",
    "print(f\"Anzahl der ursprünglichen TPP3-Paare, die jetzt in den positiven Train/Validation-Daten vorkommen: {len(tpp3_in_pos_trainval)}\")\n",
    "\n",
    "# Vergleiche, ob die TCR-Keys in den ursprünglichen TPP3-Paaren mit denen im Testset übereinstimmen\n",
    "missing_tcr_keys = original_tpp3[~original_tpp3[\"tcr_key\"].isin(test_df[\"tcr_key\"])]\n",
    "\n",
    "print(f\"Anzahl der TPP3-Paare, deren TCR-Key im Testset fehlt: {len(missing_tcr_keys)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
